{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRIPJG6Froi+oQb7tz/nQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Deep_Learning/blob/main/12_Gradient_Descent_For_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Furj5lvfv59I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/codebasics/py/master/DeepLearningML/6_gradient_descent/insurance_data.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjIrRsi0wIbW",
        "outputId": "2bb638c7-4559-4525-a653-dc94e7beb95e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DuP4s2-Lwa4u",
        "outputId": "13cb87dc-73e3-4d73-a3c0-2ed6bf33bce0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  affordibility  bought_insurance\n",
              "0   22              1                 0\n",
              "1   25              0                 0\n",
              "2   47              1                 1\n",
              "3   52              0                 0\n",
              "4   46              1                 1\n",
              "5   56              1                 1\n",
              "6   55              0                 0\n",
              "7   60              0                 1\n",
              "8   62              1                 1\n",
              "9   61              1                 1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-764511b4-9c2b-4cec-8d29-63b54d3a994b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "      <th>bought_insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-764511b4-9c2b-4cec-8d29-63b54d3a994b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-764511b4-9c2b-4cec-8d29-63b54d3a994b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-764511b4-9c2b-4cec-8d29-63b54d3a994b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd20b3f7-be96-48d1-b98f-e75319b4f2a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd20b3f7-be96-48d1-b98f-e75319b4f2a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd20b3f7-be96-48d1-b98f-e75319b4f2a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Data\n",
        "X = df.drop(['bought_insurance'], axis=\"columns\")\n",
        "y = df['bought_insurance']\n",
        "\n",
        "X['age'] = X['age'] / 100"
      ],
      "metadata": {
        "id": "8XeyYjqawdLR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "metadata": {
        "id": "tBY16G6fw0mC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Tensorflow"
      ],
      "metadata": {
        "id": "f6B1ncQ63iWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(1, input_shape=(2,), activation=\"sigmoid\", kernel_initializer = \"ones\", bias_initializer=\"zeros\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X, y, epochs = 5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9lGAqHBw4m2",
        "outputId": "c9be6e84-a584-4d11-d426-c36ee76bc54a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.7160 - accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7156 - accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7152 - accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7148 - accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7144 - accuracy: 0.5000\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7140 - accuracy: 0.5000\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7136 - accuracy: 0.5000\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7132 - accuracy: 0.5000\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7128 - accuracy: 0.5000\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7124 - accuracy: 0.5000\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7120 - accuracy: 0.5000\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7116 - accuracy: 0.5000\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7112 - accuracy: 0.5000\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7108 - accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7104 - accuracy: 0.5000\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7101 - accuracy: 0.5000\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7097 - accuracy: 0.5000\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7093 - accuracy: 0.5000\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7089 - accuracy: 0.5000\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7085 - accuracy: 0.5000\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7081 - accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7078 - accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7074 - accuracy: 0.5000\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7070 - accuracy: 0.5000\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7066 - accuracy: 0.5000\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7063 - accuracy: 0.5000\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7059 - accuracy: 0.5000\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7055 - accuracy: 0.5000\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7051 - accuracy: 0.5000\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7048 - accuracy: 0.5000\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7044 - accuracy: 0.5000\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7040 - accuracy: 0.5000\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7036 - accuracy: 0.5000\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.5000\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7025 - accuracy: 0.5000\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.5000\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7018 - accuracy: 0.5000\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7015 - accuracy: 0.5000\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.5000\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7007 - accuracy: 0.5000\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.5000\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6982 - accuracy: 0.5000\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6879 - accuracy: 0.5000\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6866 - accuracy: 0.5000\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6863 - accuracy: 0.5000\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6860 - accuracy: 0.5000\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6857 - accuracy: 0.5000\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6854 - accuracy: 0.5000\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6851 - accuracy: 0.5000\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6847 - accuracy: 0.5000\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.5000\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6841 - accuracy: 0.5000\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6838 - accuracy: 0.5000\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.5000\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6832 - accuracy: 0.5000\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6829 - accuracy: 0.5000\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.5000\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5000\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6820 - accuracy: 0.5000\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6817 - accuracy: 0.5000\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5000\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5000\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5000\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6806 - accuracy: 0.5000\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.5000\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.5000\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6797 - accuracy: 0.5000\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6794 - accuracy: 0.5000\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6791 - accuracy: 0.5000\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6788 - accuracy: 0.5000\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.5000\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.5000\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6780 - accuracy: 0.5000\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.5000\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6774 - accuracy: 0.5000\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6771 - accuracy: 0.5000\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.5000\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6766 - accuracy: 0.5000\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.5000\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.5000\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6755 - accuracy: 0.5000\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.5000\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6749 - accuracy: 0.5000\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6747 - accuracy: 0.5000\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6744 - accuracy: 0.5000\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6741 - accuracy: 0.5000\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6739 - accuracy: 0.5000\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6736 - accuracy: 0.5000\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6733 - accuracy: 0.5000\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - accuracy: 0.5000\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.5000\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6726 - accuracy: 0.5000\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6723 - accuracy: 0.5000\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6720 - accuracy: 0.5000\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6718 - accuracy: 0.5000\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.5000\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6713 - accuracy: 0.5000\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6710 - accuracy: 0.5000\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6708 - accuracy: 0.5000\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.5000\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6702 - accuracy: 0.5000\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6700 - accuracy: 0.5000\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6697 - accuracy: 0.5000\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6695 - accuracy: 0.5000\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6692 - accuracy: 0.5000\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6690 - accuracy: 0.5000\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6688 - accuracy: 0.5000\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6685 - accuracy: 0.5000\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 0.5000\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6680 - accuracy: 0.5000\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6678 - accuracy: 0.5000\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6675 - accuracy: 0.5000\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6673 - accuracy: 0.5000\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6671 - accuracy: 0.5000\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6668 - accuracy: 0.5000\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6666 - accuracy: 0.5000\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.5000\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.5000\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6659 - accuracy: 0.5000\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6656 - accuracy: 0.5000\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6654 - accuracy: 0.5000\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6652 - accuracy: 0.5000\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6649 - accuracy: 0.5000\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6647 - accuracy: 0.5000\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6645 - accuracy: 0.5000\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6642 - accuracy: 0.5000\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6640 - accuracy: 0.5000\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6638 - accuracy: 0.5000\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 0.5000\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6633 - accuracy: 0.5000\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6631 - accuracy: 0.5000\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6629 - accuracy: 0.5000\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6627 - accuracy: 0.5357\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.5357\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6622 - accuracy: 0.5357\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.5357\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6618 - accuracy: 0.5357\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6616 - accuracy: 0.5357\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6614 - accuracy: 0.5357\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.5357\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6609 - accuracy: 0.5357\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6607 - accuracy: 0.5357\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6605 - accuracy: 0.5357\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6603 - accuracy: 0.5357\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6601 - accuracy: 0.5357\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6599 - accuracy: 0.5357\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.5357\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6595 - accuracy: 0.5357\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6593 - accuracy: 0.5357\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6590 - accuracy: 0.5357\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6588 - accuracy: 0.5357\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6586 - accuracy: 0.5357\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6584 - accuracy: 0.5357\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6582 - accuracy: 0.5357\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6580 - accuracy: 0.5357\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6578 - accuracy: 0.5357\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6576 - accuracy: 0.5357\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6574 - accuracy: 0.5357\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6572 - accuracy: 0.5357\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.5357\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6568 - accuracy: 0.5357\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.5357\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6564 - accuracy: 0.5357\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6562 - accuracy: 0.5357\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6561 - accuracy: 0.5357\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6559 - accuracy: 0.5357\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6557 - accuracy: 0.5357\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6555 - accuracy: 0.5357\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6553 - accuracy: 0.5357\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6551 - accuracy: 0.5357\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 0.5357\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6547 - accuracy: 0.5357\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6545 - accuracy: 0.5357\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6544 - accuracy: 0.5357\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 0.5357\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6540 - accuracy: 0.5357\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6538 - accuracy: 0.5357\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6536 - accuracy: 0.5357\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6534 - accuracy: 0.5357\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6533 - accuracy: 0.5357\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6531 - accuracy: 0.5357\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6529 - accuracy: 0.5357\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6527 - accuracy: 0.5357\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6525 - accuracy: 0.5357\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6524 - accuracy: 0.5357\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6522 - accuracy: 0.5357\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.5357\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6518 - accuracy: 0.5357\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6517 - accuracy: 0.5357\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6515 - accuracy: 0.5357\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6513 - accuracy: 0.5357\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6511 - accuracy: 0.5357\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6510 - accuracy: 0.5714\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6508 - accuracy: 0.5714\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.5714\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6505 - accuracy: 0.5714\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6503 - accuracy: 0.5714\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6501 - accuracy: 0.5714\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6500 - accuracy: 0.5714\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6498 - accuracy: 0.5714\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6496 - accuracy: 0.5714\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6495 - accuracy: 0.6071\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.6071\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6491 - accuracy: 0.6071\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6490 - accuracy: 0.6071\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6488 - accuracy: 0.6071\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6487 - accuracy: 0.6071\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6485 - accuracy: 0.6071\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6483 - accuracy: 0.6071\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6482 - accuracy: 0.6071\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6480 - accuracy: 0.6071\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6479 - accuracy: 0.6071\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6477 - accuracy: 0.6071\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.6071\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6474 - accuracy: 0.6071\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6472 - accuracy: 0.6071\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6471 - accuracy: 0.6071\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6469 - accuracy: 0.6071\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.6071\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6466 - accuracy: 0.6429\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.6429\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6463 - accuracy: 0.6429\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6462 - accuracy: 0.6429\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6460 - accuracy: 0.6429\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6429\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6429\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6429\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6455 - accuracy: 0.6429\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.6429\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6452 - accuracy: 0.6429\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6450 - accuracy: 0.6429\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.6429\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6447 - accuracy: 0.6429\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6446 - accuracy: 0.6429\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6444 - accuracy: 0.6429\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6443 - accuracy: 0.6429\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6442 - accuracy: 0.6429\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.6429\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6439 - accuracy: 0.6429\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.6429\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6436 - accuracy: 0.6429\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6435 - accuracy: 0.6429\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6433 - accuracy: 0.6429\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6432 - accuracy: 0.6429\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6431 - accuracy: 0.6429\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6429 - accuracy: 0.6429\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.6429\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.6429\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6425 - accuracy: 0.6429\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6424 - accuracy: 0.6429\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6423 - accuracy: 0.6429\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.6429\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6420 - accuracy: 0.6429\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6419 - accuracy: 0.6429\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6418 - accuracy: 0.6429\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6416 - accuracy: 0.6429\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6415 - accuracy: 0.6429\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6414 - accuracy: 0.6429\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6412 - accuracy: 0.6429\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.6429\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6410 - accuracy: 0.6429\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6409 - accuracy: 0.6429\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6407 - accuracy: 0.6429\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6406 - accuracy: 0.6429\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.6429\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6404 - accuracy: 0.6429\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6402 - accuracy: 0.6429\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6401 - accuracy: 0.6429\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6400 - accuracy: 0.6429\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6399 - accuracy: 0.6429\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6398 - accuracy: 0.6429\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6396 - accuracy: 0.6429\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6395 - accuracy: 0.6429\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 0.6429\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6393 - accuracy: 0.6429\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6392 - accuracy: 0.6429\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6391 - accuracy: 0.6429\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.6429\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6388 - accuracy: 0.6429\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6387 - accuracy: 0.6429\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6386 - accuracy: 0.6429\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6385 - accuracy: 0.6429\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6384 - accuracy: 0.6429\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.6429\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 0.6429\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6380 - accuracy: 0.6429\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6379 - accuracy: 0.6429\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6378 - accuracy: 0.6429\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6377 - accuracy: 0.6429\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6376 - accuracy: 0.6429\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.6429\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6374 - accuracy: 0.6429\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6373 - accuracy: 0.6429\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6371 - accuracy: 0.6429\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6370 - accuracy: 0.6429\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6369 - accuracy: 0.6429\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6368 - accuracy: 0.6429\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6367 - accuracy: 0.6429\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.6429\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.6429\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.6429\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6363 - accuracy: 0.6429\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6362 - accuracy: 0.6429\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6361 - accuracy: 0.6429\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6360 - accuracy: 0.6429\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.6429\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6358 - accuracy: 0.6429\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6357 - accuracy: 0.6429\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.6429\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6355 - accuracy: 0.6429\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6354 - accuracy: 0.6429\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.6429\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6352 - accuracy: 0.6429\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6351 - accuracy: 0.6429\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6350 - accuracy: 0.6429\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6349 - accuracy: 0.6429\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.6429\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6347 - accuracy: 0.6429\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6346 - accuracy: 0.6429\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6345 - accuracy: 0.6429\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.6429\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6343 - accuracy: 0.6429\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.6429\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.6429\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.6429\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.6429\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6338 - accuracy: 0.6429\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.6429\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.6429\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6335 - accuracy: 0.6429\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6334 - accuracy: 0.6429\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6333 - accuracy: 0.6429\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6333 - accuracy: 0.6429\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6332 - accuracy: 0.6429\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6331 - accuracy: 0.6429\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.6429\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6329 - accuracy: 0.6429\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6328 - accuracy: 0.6429\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.6429\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6326 - accuracy: 0.6429\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6325 - accuracy: 0.6429\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6324 - accuracy: 0.6429\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6323 - accuracy: 0.6429\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6323 - accuracy: 0.6429\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.6429\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6321 - accuracy: 0.6429\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6320 - accuracy: 0.6429\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.6429\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6318 - accuracy: 0.6429\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6317 - accuracy: 0.6429\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6316 - accuracy: 0.6429\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6316 - accuracy: 0.6429\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.6429\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6314 - accuracy: 0.6429\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6313 - accuracy: 0.6429\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6312 - accuracy: 0.6429\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6311 - accuracy: 0.6429\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6311 - accuracy: 0.6429\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6310 - accuracy: 0.6429\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6309 - accuracy: 0.6429\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6308 - accuracy: 0.6429\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6307 - accuracy: 0.6429\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6306 - accuracy: 0.6429\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6306 - accuracy: 0.6429\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6305 - accuracy: 0.6429\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6304 - accuracy: 0.6429\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6303 - accuracy: 0.6429\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6302 - accuracy: 0.6429\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6301 - accuracy: 0.6429\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.6429\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6300 - accuracy: 0.6429\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6299 - accuracy: 0.6429\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6298 - accuracy: 0.6429\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6297 - accuracy: 0.6429\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6297 - accuracy: 0.6429\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6296 - accuracy: 0.6429\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6295 - accuracy: 0.6429\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6294 - accuracy: 0.6429\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6294 - accuracy: 0.6429\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6293 - accuracy: 0.6429\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6292 - accuracy: 0.6429\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 0.6429\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6290 - accuracy: 0.6429\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6290 - accuracy: 0.6429\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6289 - accuracy: 0.6429\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6288 - accuracy: 0.6429\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6287 - accuracy: 0.6429\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6287 - accuracy: 0.6429\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6286 - accuracy: 0.6429\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.6429\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6284 - accuracy: 0.6429\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6284 - accuracy: 0.6429\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6283 - accuracy: 0.6429\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6282 - accuracy: 0.6429\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6281 - accuracy: 0.6429\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6281 - accuracy: 0.6429\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6280 - accuracy: 0.6429\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6279 - accuracy: 0.6429\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6278 - accuracy: 0.6429\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6278 - accuracy: 0.6429\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6277 - accuracy: 0.6429\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6429\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.6429\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6275 - accuracy: 0.6429\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6274 - accuracy: 0.6429\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6273 - accuracy: 0.6429\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6273 - accuracy: 0.6429\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6272 - accuracy: 0.6429\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6271 - accuracy: 0.6429\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6270 - accuracy: 0.6429\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6270 - accuracy: 0.6429\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6269 - accuracy: 0.6429\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.6429\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.6429\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.6429\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6429\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6429\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6429\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6264 - accuracy: 0.6429\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6263 - accuracy: 0.6429\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.6429\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6262 - accuracy: 0.6429\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.6429\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.6429\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6260 - accuracy: 0.6429\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6259 - accuracy: 0.6429\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6429\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6258 - accuracy: 0.6429\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6257 - accuracy: 0.6429\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.6429\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6256 - accuracy: 0.6429\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6255 - accuracy: 0.6429\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6254 - accuracy: 0.6429\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6254 - accuracy: 0.6429\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 0.6429\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6252 - accuracy: 0.6429\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6252 - accuracy: 0.6429\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.6429\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6250 - accuracy: 0.6429\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.6429\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6249 - accuracy: 0.6429\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6248 - accuracy: 0.6429\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6248 - accuracy: 0.6429\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6247 - accuracy: 0.6429\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6246 - accuracy: 0.6429\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6246 - accuracy: 0.6429\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6245 - accuracy: 0.6429\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6245 - accuracy: 0.6429\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6244 - accuracy: 0.6429\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6243 - accuracy: 0.6429\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6243 - accuracy: 0.6429\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6242 - accuracy: 0.6429\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6241 - accuracy: 0.6429\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6241 - accuracy: 0.6429\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6240 - accuracy: 0.6429\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.6429\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6239 - accuracy: 0.6429\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.6429\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.6429\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.6429\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6236 - accuracy: 0.6429\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6235 - accuracy: 0.6429\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6235 - accuracy: 0.6429\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6234 - accuracy: 0.6429\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6234 - accuracy: 0.6429\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6233 - accuracy: 0.6429\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6232 - accuracy: 0.6429\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6232 - accuracy: 0.6429\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6231 - accuracy: 0.6429\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6230 - accuracy: 0.6429\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.6429\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.6429\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6229 - accuracy: 0.6429\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6228 - accuracy: 0.6429\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.6429\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6429\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6226 - accuracy: 0.6429\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6225 - accuracy: 0.6429\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6225 - accuracy: 0.6429\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6224 - accuracy: 0.6429\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.6429\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.6429\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6222 - accuracy: 0.6429\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6222 - accuracy: 0.6429\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.6429\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.6429\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6220 - accuracy: 0.6429\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6219 - accuracy: 0.6429\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6219 - accuracy: 0.6429\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6218 - accuracy: 0.6429\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.6429\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.6429\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.6429\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.6429\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6215 - accuracy: 0.6429\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6214 - accuracy: 0.6429\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6214 - accuracy: 0.6429\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6213 - accuracy: 0.6429\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6213 - accuracy: 0.6429\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6212 - accuracy: 0.6429\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.6429\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.6429\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.6429\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.6429\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6209 - accuracy: 0.6429\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6208 - accuracy: 0.6429\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6208 - accuracy: 0.6429\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6207 - accuracy: 0.6429\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6207 - accuracy: 0.6429\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6429\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6429\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6429\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.6429\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.6429\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6203 - accuracy: 0.6429\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6202 - accuracy: 0.6429\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6202 - accuracy: 0.6429\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6201 - accuracy: 0.6429\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6201 - accuracy: 0.6429\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6200 - accuracy: 0.6429\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6199 - accuracy: 0.6429\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6199 - accuracy: 0.6429\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6198 - accuracy: 0.6429\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6198 - accuracy: 0.6786\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6197 - accuracy: 0.6786\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6196 - accuracy: 0.6786\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6196 - accuracy: 0.6786\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6195 - accuracy: 0.6786\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6195 - accuracy: 0.6786\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6194 - accuracy: 0.6786\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6194 - accuracy: 0.6786\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6193 - accuracy: 0.6786\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6192 - accuracy: 0.6786\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6192 - accuracy: 0.6786\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6191 - accuracy: 0.6786\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6191 - accuracy: 0.6786\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6190 - accuracy: 0.6786\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6189 - accuracy: 0.6786\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6189 - accuracy: 0.6786\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6188 - accuracy: 0.6786\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6188 - accuracy: 0.6786\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.6786\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6187 - accuracy: 0.6786\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6186 - accuracy: 0.6786\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6185 - accuracy: 0.6786\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6185 - accuracy: 0.6786\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6184 - accuracy: 0.6786\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6184 - accuracy: 0.6786\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6183 - accuracy: 0.6786\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6182 - accuracy: 0.6786\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6182 - accuracy: 0.6786\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6181 - accuracy: 0.6786\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6181 - accuracy: 0.6786\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6180 - accuracy: 0.6786\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6180 - accuracy: 0.6786\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6179 - accuracy: 0.6786\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6178 - accuracy: 0.6786\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6178 - accuracy: 0.6786\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6177 - accuracy: 0.6786\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6177 - accuracy: 0.6786\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6176 - accuracy: 0.6786\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6176 - accuracy: 0.6786\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6175 - accuracy: 0.6786\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6174 - accuracy: 0.6786\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6174 - accuracy: 0.6786\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6173 - accuracy: 0.6786\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6173 - accuracy: 0.6786\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6172 - accuracy: 0.6786\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6172 - accuracy: 0.6786\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6171 - accuracy: 0.6786\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6170 - accuracy: 0.6786\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6170 - accuracy: 0.6786\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6169 - accuracy: 0.6786\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6169 - accuracy: 0.6786\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6168 - accuracy: 0.6786\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6168 - accuracy: 0.6786\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6167 - accuracy: 0.6786\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6166 - accuracy: 0.6786\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6166 - accuracy: 0.6786\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6165 - accuracy: 0.6786\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6165 - accuracy: 0.6786\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6164 - accuracy: 0.6786\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6164 - accuracy: 0.6786\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6163 - accuracy: 0.6786\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6162 - accuracy: 0.6786\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6162 - accuracy: 0.6786\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6161 - accuracy: 0.6786\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6161 - accuracy: 0.6786\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6160 - accuracy: 0.6786\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.6786\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.6786\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6158 - accuracy: 0.6786\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6158 - accuracy: 0.6786\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6157 - accuracy: 0.6786\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6157 - accuracy: 0.6786\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6156 - accuracy: 0.6786\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6156 - accuracy: 0.6786\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6155 - accuracy: 0.6786\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6154 - accuracy: 0.6786\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6154 - accuracy: 0.6786\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6153 - accuracy: 0.6786\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6153 - accuracy: 0.6786\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6152 - accuracy: 0.6786\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6152 - accuracy: 0.6786\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6151 - accuracy: 0.6786\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6151 - accuracy: 0.6786\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6150 - accuracy: 0.6786\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6149 - accuracy: 0.6786\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6149 - accuracy: 0.6786\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6148 - accuracy: 0.6786\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6148 - accuracy: 0.6786\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6147 - accuracy: 0.6786\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6147 - accuracy: 0.6786\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6146 - accuracy: 0.6786\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6145 - accuracy: 0.6786\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6145 - accuracy: 0.6786\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6144 - accuracy: 0.6786\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6144 - accuracy: 0.6786\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6143 - accuracy: 0.6786\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6143 - accuracy: 0.6786\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6142 - accuracy: 0.6786\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6141 - accuracy: 0.6786\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6141 - accuracy: 0.6786\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6140 - accuracy: 0.6786\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6140 - accuracy: 0.6786\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6139 - accuracy: 0.6786\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6139 - accuracy: 0.6786\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6138 - accuracy: 0.6786\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6138 - accuracy: 0.6786\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6137 - accuracy: 0.6786\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6136 - accuracy: 0.6786\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6136 - accuracy: 0.6786\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6135 - accuracy: 0.6786\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6135 - accuracy: 0.6786\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6134 - accuracy: 0.6786\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6134 - accuracy: 0.6786\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6133 - accuracy: 0.6786\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6132 - accuracy: 0.6786\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6132 - accuracy: 0.6786\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6131 - accuracy: 0.6786\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6131 - accuracy: 0.6786\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6130 - accuracy: 0.6786\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6130 - accuracy: 0.6786\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6129 - accuracy: 0.6786\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6128 - accuracy: 0.6786\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6128 - accuracy: 0.6786\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6127 - accuracy: 0.6786\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6127 - accuracy: 0.6786\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6126 - accuracy: 0.6786\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6126 - accuracy: 0.6786\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6125 - accuracy: 0.6786\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6125 - accuracy: 0.6786\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6124 - accuracy: 0.6786\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6123 - accuracy: 0.6786\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6123 - accuracy: 0.6786\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6122 - accuracy: 0.6786\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6122 - accuracy: 0.6786\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6121 - accuracy: 0.6786\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6121 - accuracy: 0.6786\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6120 - accuracy: 0.6786\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6119 - accuracy: 0.6786\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6119 - accuracy: 0.6786\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6118 - accuracy: 0.6786\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6118 - accuracy: 0.6786\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6117 - accuracy: 0.6786\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6117 - accuracy: 0.6786\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6116 - accuracy: 0.6786\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6116 - accuracy: 0.6786\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6115 - accuracy: 0.6786\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6114 - accuracy: 0.6786\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.6786\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6113 - accuracy: 0.6786\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6113 - accuracy: 0.6786\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6112 - accuracy: 0.6786\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6112 - accuracy: 0.6786\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.6786\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6110 - accuracy: 0.6786\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6110 - accuracy: 0.6786\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6109 - accuracy: 0.6786\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6109 - accuracy: 0.6786\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6108 - accuracy: 0.6786\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6108 - accuracy: 0.6786\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6107 - accuracy: 0.6786\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6107 - accuracy: 0.6786\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6106 - accuracy: 0.6786\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6105 - accuracy: 0.6786\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6105 - accuracy: 0.6786\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6104 - accuracy: 0.6786\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6104 - accuracy: 0.6786\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6103 - accuracy: 0.6786\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6103 - accuracy: 0.7143\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6102 - accuracy: 0.7143\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6101 - accuracy: 0.7143\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6101 - accuracy: 0.7143\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6100 - accuracy: 0.7143\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6100 - accuracy: 0.7143\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6099 - accuracy: 0.7143\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6099 - accuracy: 0.7143\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6098 - accuracy: 0.7143\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6098 - accuracy: 0.7143\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6097 - accuracy: 0.7143\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6096 - accuracy: 0.7143\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6096 - accuracy: 0.7143\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6095 - accuracy: 0.7143\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6095 - accuracy: 0.7143\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6094 - accuracy: 0.7143\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6094 - accuracy: 0.7143\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6093 - accuracy: 0.7143\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6092 - accuracy: 0.7143\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6092 - accuracy: 0.7143\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6091 - accuracy: 0.7143\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6091 - accuracy: 0.7143\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6090 - accuracy: 0.7143\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.7143\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6089 - accuracy: 0.7143\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6089 - accuracy: 0.7143\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6088 - accuracy: 0.7143\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6087 - accuracy: 0.7143\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6087 - accuracy: 0.7143\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6086 - accuracy: 0.7143\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6086 - accuracy: 0.7143\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6085 - accuracy: 0.7143\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6085 - accuracy: 0.7143\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6084 - accuracy: 0.7143\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6083 - accuracy: 0.7143\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6083 - accuracy: 0.7143\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6082 - accuracy: 0.7143\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6082 - accuracy: 0.7143\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6081 - accuracy: 0.7143\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6081 - accuracy: 0.7143\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6080 - accuracy: 0.7143\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6079 - accuracy: 0.7143\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6079 - accuracy: 0.7143\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6078 - accuracy: 0.7143\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6078 - accuracy: 0.7143\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6077 - accuracy: 0.7143\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6077 - accuracy: 0.7143\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.7143\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6076 - accuracy: 0.7143\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6075 - accuracy: 0.7143\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6074 - accuracy: 0.7143\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6074 - accuracy: 0.7143\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6073 - accuracy: 0.7143\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6073 - accuracy: 0.7143\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6072 - accuracy: 0.7143\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6072 - accuracy: 0.7143\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6071 - accuracy: 0.7143\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6070 - accuracy: 0.7143\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6070 - accuracy: 0.7143\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6069 - accuracy: 0.7143\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6069 - accuracy: 0.7143\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6068 - accuracy: 0.7143\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6068 - accuracy: 0.7143\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6067 - accuracy: 0.7143\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6067 - accuracy: 0.7143\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6066 - accuracy: 0.7143\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6065 - accuracy: 0.7143\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6065 - accuracy: 0.7143\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6064 - accuracy: 0.7143\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6064 - accuracy: 0.7143\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6063 - accuracy: 0.7143\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6063 - accuracy: 0.7143\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6062 - accuracy: 0.7143\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6061 - accuracy: 0.7143\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6061 - accuracy: 0.7143\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6060 - accuracy: 0.7143\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6060 - accuracy: 0.7143\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6059 - accuracy: 0.7143\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6059 - accuracy: 0.7143\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6058 - accuracy: 0.7143\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6057 - accuracy: 0.7143\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6057 - accuracy: 0.7143\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6056 - accuracy: 0.7143\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6056 - accuracy: 0.7143\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6055 - accuracy: 0.7143\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6055 - accuracy: 0.7143\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6054 - accuracy: 0.7143\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6054 - accuracy: 0.7143\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6053 - accuracy: 0.7143\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6052 - accuracy: 0.7143\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6052 - accuracy: 0.7143\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6051 - accuracy: 0.7143\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6051 - accuracy: 0.7143\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6050 - accuracy: 0.7143\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6050 - accuracy: 0.7143\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6049 - accuracy: 0.7143\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6048 - accuracy: 0.7143\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6048 - accuracy: 0.7143\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6047 - accuracy: 0.7143\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6047 - accuracy: 0.7143\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6046 - accuracy: 0.7143\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6046 - accuracy: 0.7143\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6045 - accuracy: 0.7143\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6044 - accuracy: 0.7143\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6044 - accuracy: 0.7143\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6043 - accuracy: 0.7143\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6043 - accuracy: 0.7143\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6042 - accuracy: 0.7143\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6042 - accuracy: 0.7143\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6041 - accuracy: 0.7143\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6040 - accuracy: 0.7143\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6040 - accuracy: 0.7143\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6039 - accuracy: 0.7143\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6039 - accuracy: 0.7143\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6038 - accuracy: 0.7143\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6038 - accuracy: 0.7143\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.7143\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6037 - accuracy: 0.7143\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6036 - accuracy: 0.7143\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6035 - accuracy: 0.7143\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6035 - accuracy: 0.7143\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6034 - accuracy: 0.7143\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6034 - accuracy: 0.7143\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6033 - accuracy: 0.7143\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6033 - accuracy: 0.7143\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6032 - accuracy: 0.7143\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6031 - accuracy: 0.7143\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.7143\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6030 - accuracy: 0.7143\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.7143\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6029 - accuracy: 0.7143\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6029 - accuracy: 0.7143\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6028 - accuracy: 0.7143\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6027 - accuracy: 0.7143\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6027 - accuracy: 0.7143\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6026 - accuracy: 0.7143\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6026 - accuracy: 0.7143\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.7143\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6025 - accuracy: 0.7143\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6024 - accuracy: 0.7143\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6023 - accuracy: 0.7143\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.7143\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6022 - accuracy: 0.7143\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6022 - accuracy: 0.7143\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6021 - accuracy: 0.7143\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6021 - accuracy: 0.7143\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6020 - accuracy: 0.7143\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6020 - accuracy: 0.7143\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6019 - accuracy: 0.7143\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6018 - accuracy: 0.7143\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6018 - accuracy: 0.7143\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 0.7143\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6017 - accuracy: 0.7143\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6016 - accuracy: 0.7143\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6016 - accuracy: 0.7143\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6015 - accuracy: 0.7143\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6014 - accuracy: 0.7143\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6014 - accuracy: 0.7143\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6013 - accuracy: 0.7143\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6013 - accuracy: 0.7143\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6012 - accuracy: 0.7143\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6012 - accuracy: 0.7143\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6011 - accuracy: 0.7143\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.7143\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6010 - accuracy: 0.7143\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6009 - accuracy: 0.7143\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.7143\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6008 - accuracy: 0.7143\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6008 - accuracy: 0.7143\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6007 - accuracy: 0.7143\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6006 - accuracy: 0.7143\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6006 - accuracy: 0.7143\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6005 - accuracy: 0.7143\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6005 - accuracy: 0.7143\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6004 - accuracy: 0.7143\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6004 - accuracy: 0.7143\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6003 - accuracy: 0.7143\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6002 - accuracy: 0.7143\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6002 - accuracy: 0.7143\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6001 - accuracy: 0.7143\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6001 - accuracy: 0.7143\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6000 - accuracy: 0.7143\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6000 - accuracy: 0.7143\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5999 - accuracy: 0.7143\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5999 - accuracy: 0.7143\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5998 - accuracy: 0.7143\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5997 - accuracy: 0.7143\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5997 - accuracy: 0.7143\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5996 - accuracy: 0.7143\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5996 - accuracy: 0.7143\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5995 - accuracy: 0.7143\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5995 - accuracy: 0.7143\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5994 - accuracy: 0.7143\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5993 - accuracy: 0.7143\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5993 - accuracy: 0.7143\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5992 - accuracy: 0.7143\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5992 - accuracy: 0.7143\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5991 - accuracy: 0.7143\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5991 - accuracy: 0.7143\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5990 - accuracy: 0.7143\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5989 - accuracy: 0.7143\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5989 - accuracy: 0.7143\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5988 - accuracy: 0.7143\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5988 - accuracy: 0.7143\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.7143\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.7143\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5986 - accuracy: 0.7143\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5985 - accuracy: 0.7143\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5985 - accuracy: 0.7143\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5984 - accuracy: 0.7143\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5984 - accuracy: 0.7143\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5983 - accuracy: 0.7143\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5983 - accuracy: 0.7143\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5982 - accuracy: 0.7143\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5981 - accuracy: 0.7143\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5981 - accuracy: 0.7143\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5980 - accuracy: 0.7143\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5980 - accuracy: 0.7143\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5979 - accuracy: 0.7143\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5979 - accuracy: 0.7143\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5978 - accuracy: 0.7143\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5977 - accuracy: 0.7143\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5977 - accuracy: 0.7143\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5976 - accuracy: 0.7143\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5976 - accuracy: 0.7143\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5975 - accuracy: 0.7143\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5975 - accuracy: 0.7143\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5974 - accuracy: 0.7143\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5973 - accuracy: 0.7143\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5973 - accuracy: 0.7143\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5972 - accuracy: 0.7143\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5972 - accuracy: 0.7143\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5971 - accuracy: 0.7143\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5971 - accuracy: 0.7143\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5970 - accuracy: 0.7143\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5969 - accuracy: 0.7143\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5969 - accuracy: 0.7143\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5968 - accuracy: 0.7143\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5968 - accuracy: 0.7143\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5967 - accuracy: 0.7143\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5967 - accuracy: 0.7143\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5966 - accuracy: 0.7143\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5966 - accuracy: 0.7143\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5965 - accuracy: 0.7143\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5964 - accuracy: 0.7143\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5964 - accuracy: 0.7143\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5963 - accuracy: 0.7143\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5963 - accuracy: 0.7143\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5962 - accuracy: 0.7143\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5962 - accuracy: 0.7143\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5961 - accuracy: 0.7143\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5960 - accuracy: 0.7143\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5960 - accuracy: 0.7143\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5959 - accuracy: 0.7143\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5959 - accuracy: 0.7143\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5958 - accuracy: 0.7143\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5958 - accuracy: 0.7143\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5957 - accuracy: 0.7143\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5956 - accuracy: 0.7143\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5956 - accuracy: 0.7143\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5955 - accuracy: 0.7143\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5955 - accuracy: 0.7143\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5954 - accuracy: 0.7143\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5954 - accuracy: 0.7143\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5953 - accuracy: 0.7143\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5952 - accuracy: 0.7143\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5952 - accuracy: 0.7143\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5951 - accuracy: 0.7143\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5951 - accuracy: 0.7143\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5950 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bfc90757cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NljqbuIPzGV2",
        "outputId": "6cab8bd2-6b1d-4c72-e38b-65b6894d55c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 725ms/step - loss: 0.7149 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7148943543434143, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGKu7KRk17Zy",
        "outputId": "04d4f706-8b49-41af-a0a6-f2fd3759218b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 408ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63664824],\n",
              "       [0.55365694],\n",
              "       [0.4059465 ],\n",
              "       [0.49732774],\n",
              "       [0.6479835 ],\n",
              "       [0.6394969 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsqVKD522UDN",
        "outputId": "bddee18d-56ac-421c-e682-aca48bc75791"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27    0\n",
              "19    0\n",
              "16    1\n",
              "6     0\n",
              "24    1\n",
              "2     1\n",
              "Name: bought_insurance, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef, intercept = model.get_weights()\n",
        "coef, intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2auq19iw2XF6",
        "outputId": "ac2d5f6e-875b-4cda-869a-00a885165573"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.2335299],\n",
              "        [0.6825526]], dtype=float32),\n",
              " array([-0.6891305], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Prediction_function(age, affordability):\n",
        "  weighted_sum = ((age / 100)  * coef[0]) + affordability * coef[1] + intercept\n",
        "  return weighted_sum[0]"
      ],
      "metadata": {
        "id": "bxba-iBPz_fO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TbQpjaYa0TOP",
        "outputId": "8d1c33f3-1b01-4bde-ee91-c7ce9a245cac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  affordibility  bought_insurance\n",
              "0   22              1                 0\n",
              "1   25              0                 0\n",
              "2   47              1                 1\n",
              "3   52              0                 0\n",
              "4   46              1                 1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb286926-8c64-499a-b1ab-23e776024276\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "      <th>bought_insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb286926-8c64-499a-b1ab-23e776024276')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb286926-8c64-499a-b1ab-23e776024276 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb286926-8c64-499a-b1ab-23e776024276');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c8836cf8-2399-4be0-ba5f-33d4cd5ebf0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8836cf8-2399-4be0-ba5f-33d4cd5ebf0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c8836cf8-2399-4be0-ba5f-33d4cd5ebf0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Prediction_function(22, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rAC_DIn0Wu4",
        "outputId": "908e331b-e12a-481a-b2b2-ffb3ef8d0a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2647987"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Prediction_function(47, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtHI_Lf20l4n",
        "outputId": "5fe9623b-c001-40a0-bc52-48ab72410d3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5731812"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Python Coding"
      ],
      "metadata": {
        "id": "mnVpaQP73m5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Log_loss(y_true, y_pred):\n",
        "  epsilon = 1e-15\n",
        "  y_pred_new = [max(i, epsilon) for i in y_pred]\n",
        "  y_pred_new = [min(i, 1-epsilon) for i in y_pred_new]\n",
        "  y_pred_new = np.array(y_pred_new)\n",
        "  result = -np.mean(y_true * np.log(y_pred_new) + (1-y_true)*np.log(1-y_pred_new))\n",
        "  return result"
      ],
      "metadata": {
        "id": "nrtCQHid3clu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Sigmoid(X):\n",
        "  result = 1 / (1+np.exp(-X))\n",
        "  return result"
      ],
      "metadata": {
        "id": "rKfCe3AHB0jj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Gradient_descent(age, affordability, y_true, epochs, loss_threshold):\n",
        "  w1 = w2 = 1\n",
        "  bias = 0\n",
        "  learning_rate = 0.01\n",
        "  n = len(age)\n",
        "\n",
        "  for i in range(epochs):\n",
        "    weighted_sum = w1*age + w2*affordability + bias\n",
        "    y_pred = Sigmoid(weighted_sum)\n",
        "    loss = Log_loss(y_true, y_pred)\n",
        "    w1d = (1/n) * np.dot(np.transpose(age), (y_pred-y_true))\n",
        "    w2d = (1/n) * np.dot(np.transpose(affordability), (y_pred - y_true))\n",
        "    bias_d = np.mean(y_pred - y_true)\n",
        "\n",
        "    w1 = w1 - learning_rate * w1d\n",
        "    w2 = w2 - learning_rate * w2d\n",
        "    bias = bias - learning_rate * bias_d\n",
        "\n",
        "    # if loss <= loss_threshold:\n",
        "    #   break\n",
        "\n",
        "    print(f\"Epochs: {epochs}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}\")\n",
        "  return w1, w2, bias"
      ],
      "metadata": {
        "id": "ZC_aU5a-CG0a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gradient_descent(X_train['age'], X_train['affordibility'], y_train, 1000, 0.4631)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nplw-plvFPc9",
        "outputId": "81f0fb72-68b8-4dce-8a20-3360f469068e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1000, w1: 0.9996559982585969, w2: 0.9990565841967777, bias: -0.0023461719492531507, loss: 0.6790992381395301\n",
            "Epochs: 1000, w1: 0.9993141513585498, w2: 0.9981168296445907, bias: -0.004686788228051092, loss: 0.6784488100614332\n",
            "Epochs: 1000, w1: 0.9989744567207537, w2: 0.9971807331505372, bias: -0.0070218560852548986, loss: 0.6778018195878256\n",
            "Epochs: 1000, w1: 0.9986369117418161, w2: 0.9962482914691542, bias: -0.009351382827180456, loss: 0.6771582527767163\n",
            "Epochs: 1000, w1: 0.9983015137942333, w2: 0.9953195013027267, bias: -0.011675375817142297, loss: 0.6765180956825471\n",
            "Epochs: 1000, w1: 0.9979682602265653, w2: 0.9943943593016007, bias: -0.013993842474996208, loss: 0.6758813343568805\n",
            "Epochs: 1000, w1: 0.997637148363613, w2: 0.9934728620644966, bias: -0.01630679027668068, loss: 0.6752479548490842\n",
            "Epochs: 1000, w1: 0.9973081755065949, w2: 0.9925550061388254, bias: -0.018614226753757235, loss: 0.6746179432070101\n",
            "Epochs: 1000, w1: 0.9969813389333253, w2: 0.9916407880210064, bias: -0.020916159492949678, loss: 0.6739912854776697\n",
            "Epochs: 1000, w1: 0.9966566358983919, w2: 0.9907302041567866, bias: -0.02321259613568235, loss: 0.6733679677079034\n",
            "Epochs: 1000, w1: 0.9963340636333351, w2: 0.9898232509415619, bias: -0.0255035443776174, loss: 0.6727479759450485\n",
            "Epochs: 1000, w1: 0.9960136193468272, w2: 0.9889199247207002, bias: -0.027789011968191155, loss: 0.6721312962375983\n",
            "Epochs: 1000, w1: 0.9956953002248523, w2: 0.9880202217898663, bias: -0.030069006710149636, loss: 0.6715179146358602\n",
            "Epochs: 1000, w1: 0.9953791034308864, w2: 0.9871241383953474, bias: -0.03234353645908323, loss: 0.6709078171926067\n",
            "Epochs: 1000, w1: 0.9950650261060786, w2: 0.9862316707343816, bias: -0.03461260912296063, loss: 0.6703009899637233\n",
            "Epochs: 1000, w1: 0.9947530653694319, w2: 0.9853428149554868, bias: -0.03687623266166205, loss: 0.66969741900885\n",
            "Epochs: 1000, w1: 0.9944432183179849, w2: 0.9844575671587918, bias: -0.039134415086511776, loss: 0.6690970903920197\n",
            "Epochs: 1000, w1: 0.9941354820269942, w2: 0.9835759233963683, bias: -0.04138716445981008, loss: 0.66849999018229\n",
            "Epochs: 1000, w1: 0.9938298535501165, w2: 0.9826978796725645, bias: -0.04363448889436464, loss: 0.6679061044543718\n",
            "Epochs: 1000, w1: 0.9935263299195917, w2: 0.9818234319443401, bias: -0.04587639655302133, loss: 0.6673154192892514\n",
            "Epochs: 1000, w1: 0.9932249081464255, w2: 0.9809525761216025, bias: -0.048112895648194653, loss: 0.6667279207748091\n",
            "Epochs: 1000, w1: 0.9929255852205733, w2: 0.9800853080675445, bias: -0.050343994441397664, loss: 0.6661435950064309\n",
            "Epochs: 1000, w1: 0.9926283581111238, w2: 0.9792216235989826, bias: -0.05256970124277158, loss: 0.6655624280876176\n",
            "Epochs: 1000, w1: 0.9923332237664831, w2: 0.9783615184866974, bias: -0.054790024410615014, loss: 0.6649844061305866\n",
            "Epochs: 1000, w1: 0.992040179114559, w2: 0.9775049884557742, bias: -0.05700497235091298, loss: 0.6644095152568694\n",
            "Epochs: 1000, w1: 0.9917492210629452, w2: 0.976652029185945, bias: -0.0592145535168656, loss: 0.6638377415979053\n",
            "Epochs: 1000, w1: 0.9914603464991064, w2: 0.975802636311932, bias: -0.061418776408416684, loss: 0.6632690712956273\n",
            "Epochs: 1000, w1: 0.9911735522905635, w2: 0.9749568054237914, bias: -0.0636176495717821, loss: 0.6627034905030447\n",
            "Epochs: 1000, w1: 0.9908888352850779, w2: 0.9741145320672585, bias: -0.06581118159897816, loss: 0.6621409853848204\n",
            "Epochs: 1000, w1: 0.9906061923108376, w2: 0.9732758117440938, bias: -0.06799938112734978, loss: 0.661581542117842\n",
            "Epochs: 1000, w1: 0.9903256201766422, w2: 0.9724406399124298, bias: -0.0701822568390988, loss: 0.6610251468917889\n",
            "Epochs: 1000, w1: 0.9900471156720888, w2: 0.9716090119871184, bias: -0.07235981746081227, loss: 0.6604717859096927\n",
            "Epochs: 1000, w1: 0.9897706755677574, w2: 0.9707809233400794, bias: -0.07453207176299075, loss: 0.6599214453884936\n",
            "Epochs: 1000, w1: 0.9894962966153971, w2: 0.9699563693006501, bias: -0.07669902855957686, loss: 0.6593741115595905\n",
            "Epochs: 1000, w1: 0.989223975548111, w2: 0.9691353451559348, bias: -0.07886069670748393, loss: 0.6588297706693861\n",
            "Epochs: 1000, w1: 0.9889537090805434, w2: 0.9683178461511552, bias: -0.08101708510612482, loss: 0.6582884089798277\n",
            "Epochs: 1000, w1: 0.9886854939090647, w2: 0.9675038674900021, bias: -0.08316820269694108, loss: 0.6577500127689401\n",
            "Epochs: 1000, w1: 0.9884193267119579, w2: 0.9666934043349864, bias: -0.08531405846293233, loss: 0.6572145683313555\n",
            "Epochs: 1000, w1: 0.9881552041496043, w2: 0.9658864518077922, bias: -0.08745466142818599, loss: 0.6566820619788379\n",
            "Epochs: 1000, w1: 0.9878931228646698, w2: 0.965083004989629, bias: -0.08959002065740741, loss: 0.6561524800407993\n",
            "Epochs: 1000, w1: 0.9876330794822902, w2: 0.964283058921585, bias: -0.09172014525545041, loss: 0.655625808864814\n",
            "Epochs: 1000, w1: 0.9873750706102575, w2: 0.963486608604981, bias: -0.09384504436684822, loss: 0.6551020348171261\n",
            "Epochs: 1000, w1: 0.987119092839206, w2: 0.9626936490017245, bias: -0.09596472717534502, loss: 0.6545811442831501\n",
            "Epochs: 1000, w1: 0.9868651427427969, w2: 0.9619041750346635, bias: -0.09807920290342788, loss: 0.6540631236679685\n",
            "Epochs: 1000, w1: 0.9866132168779053, w2: 0.961118181587942, bias: -0.10018848081185941, loss: 0.6535479593968219\n",
            "Epochs: 1000, w1: 0.9863633117848045, w2: 0.9603356635073547, bias: -0.10229257019921094, loss: 0.653035637915595\n",
            "Epochs: 1000, w1: 0.9861154239873522, w2: 0.9595566156007016, bias: -0.10439148040139634, loss: 0.652526145691297\n",
            "Epochs: 1000, w1: 0.9858695499931751, w2: 0.9587810326381444, bias: -0.10648522079120659, loss: 0.6520194692125344\n",
            "Epochs: 1000, w1: 0.9856256862938544, w2: 0.9580089093525614, bias: -0.10857380077784502, loss: 0.6515155949899819\n",
            "Epochs: 1000, w1: 0.9853838293651102, w2: 0.9572402404399034, bias: -0.11065722980646334, loss: 0.6510145095568448\n",
            "Epochs: 1000, w1: 0.9851439756669865, w2: 0.9564750205595495, bias: -0.11273551735769842, loss: 0.6505161994693175\n",
            "Epochs: 1000, w1: 0.9849061216440357, w2: 0.9557132443346625, bias: -0.11480867294721, loss: 0.6500206513070353\n",
            "Epochs: 1000, w1: 0.9846702637255024, w2: 0.9549549063525458, bias: -0.11687670612521918, loss: 0.6495278516735222\n",
            "Epochs: 1000, w1: 0.9844363983255078, w2: 0.9542000011649977, bias: -0.1189396264760478, loss: 0.6490377871966319\n",
            "Epochs: 1000, w1: 0.9842045218432331, w2: 0.9534485232886687, bias: -0.12099744361765889, loss: 0.6485504445289835\n",
            "Epochs: 1000, w1: 0.9839746306631034, w2: 0.952700467205416, bias: -0.1230501672011979, loss: 0.6480658103483928\n",
            "Epochs: 1000, w1: 0.9837467211549701, w2: 0.9519558273626597, bias: -0.12509780691053507, loss: 0.6475838713582968\n",
            "Epochs: 1000, w1: 0.9835207896742943, w2: 0.9512145981737381, bias: -0.12714037246180887, loss: 0.6471046142881728\n",
            "Epochs: 1000, w1: 0.9832968325623295, w2: 0.9504767740182627, bias: -0.1291778736029703, loss: 0.6466280258939529\n",
            "Epochs: 1000, w1: 0.983074846146303, w2: 0.9497423492424732, bias: -0.13121032011332864, loss: 0.6461540929584321\n",
            "Epochs: 1000, w1: 0.9828548267395987, w2: 0.9490113181595928, bias: -0.1332377218030979, loss: 0.6456828022916724\n",
            "Epochs: 1000, w1: 0.982636770641938, w2: 0.9482836750501819, bias: -0.1352600885129448, loss: 0.6452141407313986\n",
            "Epochs: 1000, w1: 0.982420674139561, w2: 0.9475594141624925, bias: -0.13727743011353785, loss: 0.6447480951433916\n",
            "Epochs: 1000, w1: 0.9822065335054077, w2: 0.9468385297128222, bias: -0.13928975650509753, loss: 0.6442846524218747\n",
            "Epochs: 1000, w1: 0.9819943449992974, w2: 0.9461210158858674, bias: -0.14129707761694785, loss: 0.6438237994898951\n",
            "Epochs: 1000, w1: 0.9817841048681097, w2: 0.9454068668350762, bias: -0.14329940340706918, loss: 0.6433655232996986\n",
            "Epochs: 1000, w1: 0.9815758093459634, w2: 0.9446960766830014, bias: -0.14529674386165234, loss: 0.6429098108331016\n",
            "Epochs: 1000, w1: 0.9813694546543956, w2: 0.9439886395216518, bias: -0.14728910899465414, loss: 0.6424566491018545\n",
            "Epochs: 1000, w1: 0.9811650370025404, w2: 0.9432845494128447, bias: -0.14927650884735416, loss: 0.6420060251480016\n",
            "Epochs: 1000, w1: 0.9809625525873072, w2: 0.9425838003885562, bias: -0.15125895348791304, loss: 0.6415579260442359\n",
            "Epochs: 1000, w1: 0.9807619975935582, w2: 0.9418863864512719, bias: -0.15323645301093214, loss: 0.641112338894247\n",
            "Epochs: 1000, w1: 0.9805633681942856, w2: 0.9411923015743372, bias: -0.15520901753701466, loss: 0.6406692508330649\n",
            "Epochs: 1000, w1: 0.9803666605507885, w2: 0.9405015397023062, bias: -0.15717665721232824, loss: 0.6402286490273978\n",
            "Epochs: 1000, w1: 0.9801718708128488, w2: 0.9398140947512902, bias: -0.1591393822081691, loss: 0.6397905206759654\n",
            "Epochs: 1000, w1: 0.9799789951189074, w2: 0.9391299606093061, bias: -0.16109720272052763, loss: 0.6393548530098254\n",
            "Epochs: 1000, w1: 0.9797880295962386, w2: 0.9384491311366235, bias: -0.1630501289696557, loss: 0.6389216332926962\n",
            "Epochs: 1000, w1: 0.9795989703611252, w2: 0.9377716001661112, bias: -0.1649981711996353, loss: 0.6384908488212738\n",
            "Epochs: 1000, w1: 0.9794118135190325, w2: 0.9370973615035828, bias: -0.16694133967794902, loss: 0.6380624869255427\n",
            "Epochs: 1000, w1: 0.9792265551647819, w2: 0.9364264089281424, bias: -0.16887964469505204, loss: 0.637636534969083\n",
            "Epochs: 1000, w1: 0.9790431913827232, w2: 0.9357587361925283, bias: -0.17081309656394578, loss: 0.6372129803493712\n",
            "Epochs: 1000, w1: 0.9788617182469079, w2: 0.9350943370234562, bias: -0.17274170561975322, loss: 0.6367918104980762\n",
            "Epochs: 1000, w1: 0.9786821318212602, w2: 0.9344332051219626, bias: -0.17466548221929598, loss: 0.6363730128813493\n",
            "Epochs: 1000, w1: 0.9785044281597483, w2: 0.9337753341637455, bias: -0.17658443674067306, loss: 0.6359565750001112\n",
            "Epochs: 1000, w1: 0.9783286033065548, w2: 0.9331207177995059, bias: -0.17849857958284132, loss: 0.6355424843903309\n",
            "Epochs: 1000, w1: 0.9781546532962472, w2: 0.9324693496552873, bias: -0.18040792116519772, loss: 0.6351307286233024\n",
            "Epochs: 1000, w1: 0.9779825741539463, w2: 0.9318212233328148, bias: -0.18231247192716338, loss: 0.6347212953059139\n",
            "Epochs: 1000, w1: 0.9778123618954955, w2: 0.931176332409833, bias: -0.18421224232776937, loss: 0.6343141720809132\n",
            "Epochs: 1000, w1: 0.9776440125276283, w2: 0.9305346704404429, bias: -0.18610724284524438, loss: 0.633909346627168\n",
            "Epochs: 1000, w1: 0.9774775220481361, w2: 0.9298962309554378, bias: -0.18799748397660426, loss: 0.6335068066599215\n",
            "Epochs: 1000, w1: 0.9773128864460342, w2: 0.9292610074626386, bias: -0.18988297623724332, loss: 0.6331065399310409\n",
            "Epochs: 1000, w1: 0.9771501017017283, w2: 0.928628993447227, bias: -0.1917637301605275, loss: 0.6327085342292649\n",
            "Epochs: 1000, w1: 0.9769891637871796, w2: 0.928000182372079, bias: -0.19363975629738964, loss: 0.6323127773804413\n",
            "Epochs: 1000, w1: 0.9768300686660693, w2: 0.927374567678096, bias: -0.19551106521592637, loss: 0.6319192572477643\n",
            "Epochs: 1000, w1: 0.9766728122939626, w2: 0.9267521427845357, bias: -0.19737766750099717, loss: 0.631527961732004\n",
            "Epochs: 1000, w1: 0.9765173906184719, w2: 0.9261329010893414, bias: -0.19923957375382517, loss: 0.6311388787717318\n",
            "Epochs: 1000, w1: 0.976363799579419, w2: 0.9255168359694707, bias: -0.20109679459160015, loss: 0.6307519963435418\n",
            "Epochs: 1000, w1: 0.9762120351089972, w2: 0.9249039407812218, bias: -0.20294934064708325, loss: 0.6303673024622658\n",
            "Epochs: 1000, w1: 0.976062093131932, w2: 0.9242942088605602, bias: -0.20479722256821392, loss: 0.6299847851811853\n",
            "Epochs: 1000, w1: 0.9759139695656416, w2: 0.923687633523443, bias: -0.20664045101771866, loss: 0.629604432592237\n",
            "Epochs: 1000, w1: 0.9757676603203961, w2: 0.9230842080661423, bias: -0.208479036672722, loss: 0.6292262328262148\n",
            "Epochs: 1000, w1: 0.9756231612994766, w2: 0.9224839257655679, bias: -0.2103129902243593, loss: 0.6288501740529671\n",
            "Epochs: 1000, w1: 0.975480468399333, w2: 0.9218867798795878, bias: -0.21214232237739178, loss: 0.6284762444815883\n",
            "Epochs: 1000, w1: 0.9753395775097413, w2: 0.921292763647348, bias: -0.21396704384982349, loss: 0.6281044323606076\n",
            "Epochs: 1000, w1: 0.9752004845139601, w2: 0.9207018702895913, bias: -0.21578716537252043, loss: 0.6277347259781704\n",
            "Epochs: 1000, w1: 0.9750631852888862, w2: 0.9201140930089735, bias: -0.21760269768883173, loss: 0.6273671136622183\n",
            "Epochs: 1000, w1: 0.9749276757052097, w2: 0.91952942499038, bias: -0.21941365155421289, loss: 0.6270015837806624\n",
            "Epochs: 1000, w1: 0.9747939516275675, w2: 0.91894785940124, bias: -0.22122003773585125, loss: 0.6266381247415524\n",
            "Epochs: 1000, w1: 0.9746620089146978, w2: 0.9183693893918392, bias: -0.22302186701229346, loss: 0.6262767249932429\n",
            "Epochs: 1000, w1: 0.9745318434195914, w2: 0.9177940080956318, bias: -0.22481915017307513, loss: 0.6259173730245512\n",
            "Epochs: 1000, w1: 0.9744034509896441, w2: 0.9172217086295508, bias: -0.2266118980183527, loss: 0.6255600573649169\n",
            "Epochs: 1000, w1: 0.9742768274668073, w2: 0.9166524840943167, bias: -0.22840012135853727, loss: 0.6252047665845506\n",
            "Epochs: 1000, w1: 0.9741519686877385, w2: 0.9160863275747448, bias: -0.2301838310139309, loss: 0.6248514892945831\n",
            "Epochs: 1000, w1: 0.9740288704839499, w2: 0.9155232321400522, bias: -0.23196303781436473, loss: 0.6245002141472076\n",
            "Epochs: 1000, w1: 0.9739075286819575, w2: 0.9149631908441608, bias: -0.2337377525988396, loss: 0.6241509298358188\n",
            "Epochs: 1000, w1: 0.9737879391034283, w2: 0.914406196726002, bias: -0.2355079862151687, loss: 0.6238036250951466\n",
            "Epochs: 1000, w1: 0.9736700975653271, w2: 0.9138522428098174, bias: -0.23727374951962232, loss: 0.6234582887013886\n",
            "Epochs: 1000, w1: 0.9735539998800626, w2: 0.9133013221054592, bias: -0.23903505337657519, loss: 0.6231149094723335\n",
            "Epochs: 1000, w1: 0.9734396418556327, w2: 0.9127534276086895, bias: -0.24079190865815553, loss: 0.6227734762674847\n",
            "Epochs: 1000, w1: 0.9733270192957679, w2: 0.9122085523014763, bias: -0.2425443262438968, loss: 0.6224339779881777\n",
            "Epochs: 1000, w1: 0.9732161280000757, w2: 0.9116666891522905, bias: -0.2442923170203913, loss: 0.622096403577694\n",
            "Epochs: 1000, w1: 0.9731069637641826, w2: 0.9111278311163993, bias: -0.24603589188094635, loss: 0.6217607420213708\n",
            "Epochs: 1000, w1: 0.9729995223798757, w2: 0.9105919711361586, bias: -0.2477750617252423, loss: 0.6214269823467063\n",
            "Epochs: 1000, w1: 0.972893799635244, w2: 0.910059102141305, bias: -0.2495098374589933, loss: 0.6210951136234627\n",
            "Epochs: 1000, w1: 0.9727897913148177, w2: 0.9095292170492445, bias: -0.25124022999360984, loss: 0.6207651249637621\n",
            "Epochs: 1000, w1: 0.9726874931997077, w2: 0.9090023087653407, bias: -0.25296625024586394, loss: 0.6204370055221823\n",
            "Epochs: 1000, w1: 0.972586901067744, w2: 0.9084783701832015, bias: -0.25468790913755635, loss: 0.6201107444958452\n",
            "Epochs: 1000, w1: 0.9724880106936126, w2: 0.9079573941849637, bias: -0.2564052175951861, loss: 0.6197863311245042\n",
            "Epochs: 1000, w1: 0.972390817848992, w2: 0.9074393736415758, bias: -0.25811818654962243, loss: 0.6194637546906263\n",
            "Epochs: 1000, w1: 0.9722953183026891, w2: 0.9069243014130803, bias: -0.2598268269357788, loss: 0.6191430045194702\n",
            "Epochs: 1000, w1: 0.9722015078207739, w2: 0.9064121703488934, bias: -0.26153114969228936, loss: 0.6188240699791612\n",
            "Epochs: 1000, w1: 0.9721093821667128, w2: 0.9059029732880834, bias: -0.2632311657611877, loss: 0.6185069404807634\n",
            "Epochs: 1000, w1: 0.9720189371015023, w2: 0.9053967030596475, bias: -0.2649268860875877, loss: 0.6181916054783465\n",
            "Epochs: 1000, w1: 0.9719301683838003, w2: 0.9048933524827868, bias: -0.2666183216193669, loss: 0.6178780544690493\n",
            "Epochs: 1000, w1: 0.9718430717700577, w2: 0.9043929143671802, bias: -0.26830548330685206, loss: 0.6175662769931406\n",
            "Epochs: 1000, w1: 0.9717576430146486, w2: 0.9038953815132558, bias: -0.2699883821025071, loss: 0.6172562626340763\n",
            "Epochs: 1000, w1: 0.9716738778699997, w2: 0.9034007467124614, bias: -0.2716670289606231, loss: 0.6169480010185512\n",
            "Epochs: 1000, w1: 0.9715917720867185, w2: 0.902909002747533, bias: -0.273341434837011, loss: 0.6166414818165509\n",
            "Epochs: 1000, w1: 0.9715113214137213, w2: 0.9024201423927619, bias: -0.27501161068869623, loss: 0.6163366947413961\n",
            "Epochs: 1000, w1: 0.9714325215983596, w2: 0.9019341584142595, bias: -0.2766775674736158, loss: 0.6160336295497864\n",
            "Epochs: 1000, w1: 0.9713553683865458, w2: 0.9014510435702212, bias: -0.2783393161503179, loss: 0.6157322760418404\n",
            "Epochs: 1000, w1: 0.9712798575228786, w2: 0.9009707906111882, bias: -0.27999686767766324, loss: 0.6154326240611305\n",
            "Epochs: 1000, w1: 0.9712059847507664, w2: 0.9004933922803077, bias: -0.28165023301452946, loss: 0.6151346634947171\n",
            "Epochs: 1000, w1: 0.9711337458125505, w2: 0.9000188413135913, bias: -0.2832994231195172, loss: 0.6148383842731772\n",
            "Epochs: 1000, w1: 0.9710631364496276, w2: 0.8995471304401723, bias: -0.28494444895065885, loss: 0.6145437763706315\n",
            "Epochs: 1000, w1: 0.9709941524025708, w2: 0.8990782523825602, bias: -0.28658532146512933, loss: 0.6142508298047672\n",
            "Epochs: 1000, w1: 0.97092678941125, w2: 0.8986121998568946, bias: -0.2882220516189595, loss: 0.6139595346368579\n",
            "Epochs: 1000, w1: 0.9708610432149514, w2: 0.8981489655731966, bias: -0.2898546503667515, loss: 0.6136698809717812\n",
            "Epochs: 1000, w1: 0.970796909552496, w2: 0.8976885422356192, bias: -0.291483128661397, loss: 0.6133818589580315\n",
            "Epochs: 1000, w1: 0.9707343841623576, w2: 0.8972309225426955, bias: -0.2931074974537968, loss: 0.6130954587877316\n",
            "Epochs: 1000, w1: 0.9706734627827789, w2: 0.8967760991875852, bias: -0.29472776769258374, loss: 0.6128106706966396\n",
            "Epochs: 1000, w1: 0.970614141151888, w2: 0.8963240648583194, bias: -0.2963439503238473, loss: 0.6125274849641548\n",
            "Epochs: 1000, w1: 0.9705564150078132, w2: 0.8958748122380442, bias: -0.2979560562908606, loss: 0.6122458919133179\n",
            "Epochs: 1000, w1: 0.9705002800887965, w2: 0.8954283340052619, bias: -0.2995640965338097, loss: 0.6119658819108114\n",
            "Epochs: 1000, w1: 0.9704457321333074, w2: 0.8949846228340709, bias: -0.3011680819895255, loss: 0.6116874453669546\n",
            "Epochs: 1000, w1: 0.970392766880155, w2: 0.8945436713944034, bias: -0.30276802359121735, loss: 0.6114105727356971\n",
            "Epochs: 1000, w1: 0.9703413800685989, w2: 0.8941054723522622, bias: -0.30436393226820946, loss: 0.6111352545146095\n",
            "Epochs: 1000, w1: 0.9702915674384603, w2: 0.8936700183699552, bias: -0.30595581894567936, loss: 0.6108614812448698\n",
            "Epochs: 1000, w1: 0.970243324730231, w2: 0.8932373021063277, bias: -0.3075436945443986, loss: 0.6105892435112495\n",
            "Epochs: 1000, w1: 0.9701966476851822, w2: 0.8928073162169944, bias: -0.30912756998047597, loss: 0.6103185319420956\n",
            "Epochs: 1000, w1: 0.9701515320454722, w2: 0.8923800533545682, bias: -0.31070745616510265, loss: 0.6100493372093083\n",
            "Epochs: 1000, w1: 0.9701079735542534, w2: 0.8919555061688881, bias: -0.31228336400429996, loss: 0.6097816500283201\n",
            "Epochs: 1000, w1: 0.9700659679557778, w2: 0.8915336673072454, bias: -0.31385530439866904, loss: 0.6095154611580691\n",
            "Epochs: 1000, w1: 0.9700255109955027, w2: 0.8911145294146076, bias: -0.3154232882431432, loss: 0.6092507614009698\n",
            "Epochs: 1000, w1: 0.9699865984201941, w2: 0.890698085133841, bias: -0.31698732642674204, loss: 0.6089875416028833\n",
            "Epochs: 1000, w1: 0.9699492259780305, w2: 0.8902843271059317, bias: -0.31854742983232837, loss: 0.6087257926530838\n",
            "Epochs: 1000, w1: 0.9699133894187049, w2: 0.8898732479702046, bias: -0.3201036093363668, loss: 0.6084655054842218\n",
            "Epochs: 1000, w1: 0.9698790844935263, w2: 0.8894648403645405, bias: -0.321655875808685, loss: 0.608206671072287\n",
            "Epochs: 1000, w1: 0.9698463069555208, w2: 0.8890590969255922, bias: -0.32320424011223703, loss: 0.6079492804365665\n",
            "Epochs: 1000, w1: 0.9698150525595302, w2: 0.8886560102889978, bias: -0.32474871310286896, loss: 0.6076933246396022\n",
            "Epochs: 1000, w1: 0.9697853170623119, w2: 0.8882555730895936, bias: -0.32628930562908653, loss: 0.607438794787146\n",
            "Epochs: 1000, w1: 0.969757096222636, w2: 0.8878577779616239, bias: -0.32782602853182535, loss: 0.6071856820281106\n",
            "Epochs: 1000, w1: 0.9697303858013828, w2: 0.8874626175389505, bias: -0.329358892644223, loss: 0.6069339775545208\n",
            "Epochs: 1000, w1: 0.9697051815616389, w2: 0.887070084455259, bias: -0.33088790879139357, loss: 0.6066836726014609\n",
            "Epochs: 1000, w1: 0.969681479268792, w2: 0.8866801713442646, bias: -0.3324130877902041, loss: 0.6064347584470199\n",
            "Epochs: 1000, w1: 0.969659274690626, w2: 0.8862928708399155, bias: -0.3339344404490538, loss: 0.6061872264122354\n",
            "Epochs: 1000, w1: 0.9696385635974137, w2: 0.8859081755765951, bias: -0.33545197756765455, loss: 0.6059410678610345\n",
            "Epochs: 1000, w1: 0.9696193417620104, w2: 0.8855260781893218, bias: -0.3369657099368146, loss: 0.6056962742001734\n",
            "Epochs: 1000, w1: 0.9696016049599445, w2: 0.885146571313948, bias: -0.3384756483382235, loss: 0.6054528368791735\n",
            "Epochs: 1000, w1: 0.9695853489695094, w2: 0.8847696475873565, bias: -0.33998180354424007, loss: 0.6052107473902576\n",
            "Epochs: 1000, w1: 0.9695705695718531, w2: 0.8843952996476558, bias: -0.3414841863176817, loss: 0.6049699972682826\n",
            "Epochs: 1000, w1: 0.9695572625510672, w2: 0.8840235201343737, bias: -0.34298280741161646, loss: 0.6047305780906695\n",
            "Epochs: 1000, w1: 0.9695454236942758, w2: 0.8836543016886484, bias: -0.34447767756915704, loss: 0.6044924814773343\n",
            "Epochs: 1000, w1: 0.969535048791722, w2: 0.8832876369534195, bias: -0.3459688075232567, loss: 0.6042556990906133\n",
            "Epochs: 1000, w1: 0.9695261336368555, w2: 0.8829235185736156, bias: -0.34745620799650784, loss: 0.6040202226351901\n",
            "Epochs: 1000, w1: 0.9695186740264176, w2: 0.8825619391963413, bias: -0.34893988970094214, loss: 0.6037860438580168\n",
            "Epochs: 1000, w1: 0.9695126657605263, w2: 0.8822028914710621, bias: -0.3504198633378331, loss: 0.603553154548239\n",
            "Epochs: 1000, w1: 0.9695081046427606, w2: 0.881846368049788, bias: -0.35189613959750066, loss: 0.6033215465371115\n",
            "Epochs: 1000, w1: 0.9695049864802434, w2: 0.8814923615872547, bias: -0.35336872915911793, loss: 0.6030912116979192\n",
            "Epochs: 1000, w1: 0.9695033070837238, w2: 0.8811408647411043, bias: -0.35483764269052, loss: 0.6028621419458933\n",
            "Epochs: 1000, w1: 0.9695030622676587, w2: 0.8807918701720628, bias: -0.35630289084801453, loss: 0.6026343292381235\n",
            "Epochs: 1000, w1: 0.9695042478502935, w2: 0.8804453705441176, bias: -0.3577644842761951, loss: 0.6024077655734739\n",
            "Epochs: 1000, w1: 0.9695068596537422, w2: 0.8801013585246922, bias: -0.3592224336077559, loss: 0.6021824429924917\n",
            "Epochs: 1000, w1: 0.9695108935040656, w2: 0.8797598267848195, bias: -0.3606767494633089, loss: 0.6019583535773191\n",
            "Epochs: 1000, w1: 0.9695163452313504, w2: 0.8794207679993136, bias: -0.36212744245120293, loss: 0.6017354894515989\n",
            "Epochs: 1000, w1: 0.9695232106697861, w2: 0.8790841748469403, bias: -0.3635745231673448, loss: 0.6015138427803837\n",
            "Epochs: 1000, w1: 0.9695314856577414, w2: 0.8787500400105852, bias: -0.36501800219502245, loss: 0.601293405770038\n",
            "Epochs: 1000, w1: 0.9695411660378402, w2: 0.8784183561774207, bias: -0.36645789010473023, loss: 0.6010741706681438\n",
            "Epochs: 1000, w1: 0.9695522476570365, w2: 0.8780891160390712, bias: -0.36789419745399604, loss: 0.6008561297634013\n",
            "Epochs: 1000, w1: 0.9695647263666882, w2: 0.8777623122917771, bias: -0.36932693478721035, loss: 0.6006392753855301\n",
            "Epochs: 1000, w1: 0.9695785980226307, w2: 0.8774379376365563, bias: -0.37075611263545766, loss: 0.6004235999051678\n",
            "Epochs: 1000, w1: 0.9695938584852491, w2: 0.8771159847793649, bias: -0.3721817415163495, loss: 0.6002090957337678\n",
            "Epochs: 1000, w1: 0.9696105036195503, w2: 0.8767964464312563, bias: -0.37360383193385954, loss: 0.5999957553234954\n",
            "Epochs: 1000, w1: 0.9696285292952331, w2: 0.876479315308538, bias: -0.3750223943781609, loss: 0.5997835711671233\n",
            "Epochs: 1000, w1: 0.9696479313867594, w2: 0.8761645841329273, bias: -0.3764374393254648, loss: 0.5995725357979248\n",
            "Epochs: 1000, w1: 0.9696687057734223, w2: 0.8758522456317059, bias: -0.37784897723786204, loss: 0.5993626417895658\n",
            "Epochs: 1000, w1: 0.9696908483394157, w2: 0.8755422925378719, bias: -0.37925701856316557, loss: 0.5991538817559967\n",
            "Epochs: 1000, w1: 0.9697143549739009, w2: 0.8752347175902907, bias: -0.38066157373475545, loss: 0.5989462483513418\n",
            "Epochs: 1000, w1: 0.9697392215710747, w2: 0.8749295135338448, bias: -0.38206265317142574, loss: 0.5987397342697872\n",
            "Epochs: 1000, w1: 0.9697654440302347, w2: 0.8746266731195815, bias: -0.3834602672772329, loss: 0.5985343322454699\n",
            "Epochs: 1000, w1: 0.9697930182558451, w2: 0.8743261891048588, bias: -0.38485442644134665, loss: 0.5983300350523623\n",
            "Epochs: 1000, w1: 0.9698219401576011, w2: 0.8740280542534906, bias: -0.3862451410379022, loss: 0.5981268355041585\n",
            "Epochs: 1000, w1: 0.9698522056504932, w2: 0.8737322613358895, bias: -0.38763242142585463, loss: 0.5979247264541573\n",
            "Epochs: 1000, w1: 0.9698838106548697, w2: 0.8734388031292091, bias: -0.38901627794883514, loss: 0.5977237007951468\n",
            "Epochs: 1000, w1: 0.9699167510964996, w2: 0.8731476724174833, bias: -0.39039672093500905, loss: 0.597523751459284\n",
            "Epochs: 1000, w1: 0.9699510229066335, w2: 0.8728588619917655, bias: -0.39177376069693554, loss: 0.5973248714179774\n",
            "Epochs: 1000, w1: 0.9699866220220653, w2: 0.8725723646502658, bias: -0.3931474075314297, loss: 0.5971270536817662\n",
            "Epochs: 1000, w1: 0.9700235443851917, w2: 0.8722881731984862, bias: -0.39451767171942564, loss: 0.5969302913001984\n",
            "Epochs: 1000, w1: 0.9700617859440717, w2: 0.8720062804493549, bias: -0.39588456352584217, loss: 0.5967345773617101\n",
            "Epochs: 1000, w1: 0.9701013426524852, w2: 0.8717266792233591, bias: -0.3972480931994498, loss: 0.5965399049935008\n",
            "Epochs: 1000, w1: 0.970142210469991, w2: 0.8714493623486761, bias: -0.3986082709727398, loss: 0.5963462673614108\n",
            "Epochs: 1000, w1: 0.970184385361984, w2: 0.8711743226613027, bias: -0.39996510706179467, loss: 0.5961536576697951\n",
            "Epochs: 1000, w1: 0.9702278632997512, w2: 0.8709015530051838, bias: -0.40131861166616084, loss: 0.5959620691613979\n",
            "Epochs: 1000, w1: 0.9702726402605278, w2: 0.8706310462323389, bias: -0.40266879496872293, loss: 0.5957714951172266\n",
            "Epochs: 1000, w1: 0.9703187122275523, w2: 0.8703627952029875, bias: -0.4040156671355797, loss: 0.5955819288564234\n",
            "Epochs: 1000, w1: 0.9703660751901202, w2: 0.8700967927856731, bias: -0.40535923831592163, loss: 0.5953933637361368\n",
            "Epochs: 1000, w1: 0.9704147251436382, w2: 0.8698330318573851, bias: -0.4066995186419106, loss: 0.5952057931513939\n",
            "Epochs: 1000, w1: 0.9704646580896769, w2: 0.8695715053036805, bias: -0.4080365182285611, loss: 0.5950192105349692\n",
            "Epochs: 1000, w1: 0.9705158700360222, w2: 0.869312206018803, bias: -0.4093702471736228, loss: 0.5948336093572537\n",
            "Epochs: 1000, w1: 0.9705683569967283, w2: 0.869055126905801, bias: -0.41070071555746557, loss: 0.5946489831261252\n",
            "Epochs: 1000, w1: 0.9706221149921668, w2: 0.8688002608766451, bias: -0.4120279334429653, loss: 0.5944653253868145\n",
            "Epochs: 1000, w1: 0.970677140049078, w2: 0.8685476008523424, bias: -0.4133519108753922, loss: 0.5942826297217734\n",
            "Epochs: 1000, w1: 0.9707334282006197, w2: 0.8682971397630515, bias: -0.4146726578823002, loss: 0.5941008897505412\n",
            "Epochs: 1000, w1: 0.9707909754864159, w2: 0.868048870548194, bias: -0.4159901844734183, loss: 0.5939200991296107\n",
            "Epochs: 1000, w1: 0.9708497779526052, w2: 0.8678027861565668, bias: -0.41730450064054336, loss: 0.5937402515522936\n",
            "Epochs: 1000, w1: 0.9709098316518877, w2: 0.8675588795464508, bias: -0.4186156163574348, loss: 0.5935613407485838\n",
            "Epochs: 1000, w1: 0.9709711326435722, w2: 0.8673171436857202, bias: -0.4199235415797106, loss: 0.5933833604850243\n",
            "Epochs: 1000, w1: 0.9710336769936218, w2: 0.8670775715519492, bias: -0.42122828624474506, loss: 0.5932063045645684\n",
            "Epochs: 1000, w1: 0.9710974607746994, w2: 0.8668401561325176, bias: -0.4225298602715682, loss: 0.5930301668264426\n",
            "Epochs: 1000, w1: 0.9711624800662125, w2: 0.8666048904247159, bias: -0.4238282735607667, loss: 0.5928549411460113\n",
            "Epochs: 1000, w1: 0.9712287309543574, w2: 0.8663717674358473, bias: -0.4251235359943864, loss: 0.5926806214346358\n",
            "Epochs: 1000, w1: 0.9712962095321619, w2: 0.8661407801833305, bias: -0.4264156574358364, loss: 0.5925072016395384\n",
            "Epochs: 1000, w1: 0.9713649118995291, w2: 0.8659119216947995, bias: -0.4277046477297948, loss: 0.5923346757436613\n",
            "Epochs: 1000, w1: 0.9714348341632788, w2: 0.8656851850082028, bias: -0.4289905167021155, loss: 0.592163037765528\n",
            "Epochs: 1000, w1: 0.9715059724371893, w2: 0.8654605631719015, bias: -0.4302732741597375, loss: 0.5919922817591039\n",
            "Epochs: 1000, w1: 0.9715783228420379, w2: 0.8652380492447654, bias: -0.43155292989059457, loss: 0.5918224018136551\n",
            "Epochs: 1000, w1: 0.971651881505642, w2: 0.8650176362962689, bias: -0.43282949366352735, loss: 0.5916533920536076\n",
            "Epochs: 1000, w1: 0.9717266445628974, w2: 0.8647993174065843, bias: -0.4341029752281965, loss: 0.5914852466384066\n",
            "Epochs: 1000, w1: 0.9718026081558185, w2: 0.8645830856666747, bias: -0.43537338431499745, loss: 0.5913179597623749\n",
            "Epochs: 1000, w1: 0.9718797684335764, w2: 0.8643689341783858, bias: -0.43664073063497644, loss: 0.591151525654571\n",
            "Epochs: 1000, w1: 0.9719581215525359, w2: 0.8641568560545355, bias: -0.4379050238797485, loss: 0.5909859385786462\n",
            "Epochs: 1000, w1: 0.9720376636762939, w2: 0.8639468444190035, bias: -0.4391662737214164, loss: 0.5908211928327037\n",
            "Epochs: 1000, w1: 0.9721183909757148, w2: 0.8637388924068182, bias: -0.4404244898124914, loss: 0.5906572827491534\n",
            "Epochs: 1000, w1: 0.9722002996289675, w2: 0.863532993164244, bias: -0.44167968178581485, loss: 0.5904942026945714\n",
            "Epochs: 1000, w1: 0.9722833858215599, w2: 0.8633291398488662, bias: -0.44293185925448225, loss: 0.590331947069554\n",
            "Epochs: 1000, w1: 0.9723676457463744, w2: 0.8631273256296748, bias: -0.4441810318117677, loss: 0.5901705103085758\n",
            "Epochs: 1000, w1: 0.9724530756037014, w2: 0.8629275436871476, bias: -0.4454272090310502, loss: 0.5900098868798453\n",
            "Epochs: 1000, w1: 0.9725396716012739, w2: 0.8627297872133323, bias: -0.44667040046574147, loss: 0.5898500712851605\n",
            "Epochs: 1000, w1: 0.9726274299542995, w2: 0.8625340494119258, bias: -0.4479106156492148, loss: 0.5896910580597642\n",
            "Epochs: 1000, w1: 0.9727163468854936, w2: 0.8623403234983545, bias: -0.4491478640947356, loss: 0.5895328417722009\n",
            "Epochs: 1000, w1: 0.972806418625111, w2: 0.8621486026998523, bias: -0.4503821552953931, loss: 0.5893754170241701\n",
            "Epochs: 1000, w1: 0.9728976414109773, w2: 0.8619588802555367, bias: -0.45161349872403345, loss: 0.5892187784503825\n",
            "Epochs: 1000, w1: 0.9729900114885199, w2: 0.8617711494164857, bias: -0.4528419038331943, loss: 0.5890629207184152\n",
            "Epochs: 1000, w1: 0.9730835251107979, w2: 0.8615854034458118, bias: -0.4540673800550404, loss: 0.588907838528565\n",
            "Epochs: 1000, w1: 0.9731781785385318, w2: 0.8614016356187354, bias: -0.45528993680130087, loss: 0.5887535266137047\n",
            "Epochs: 1000, w1: 0.9732739680401332, w2: 0.8612198392226577, bias: -0.4565095834632076, loss: 0.5885999797391366\n",
            "Epochs: 1000, w1: 0.9733708898917327, w2: 0.8610400075572312, bias: -0.4577263294114347, loss: 0.5884471927024473\n",
            "Epochs: 1000, w1: 0.9734689403772083, w2: 0.8608621339344307, bias: -0.45894018399604, loss: 0.5882951603333616\n",
            "Epochs: 1000, w1: 0.973568115788213, w2: 0.8606862116786215, bias: -0.4601511565464067, loss: 0.5881438774935972\n",
            "Epochs: 1000, w1: 0.9736684124242014, w2: 0.8605122341266278, bias: -0.46135925637118747, loss: 0.5879933390767188\n",
            "Epochs: 1000, w1: 0.9737698265924568, w2: 0.8603401946277994, bias: -0.46256449275824885, loss: 0.587843540007992\n",
            "Epochs: 1000, w1: 0.9738723546081166, w2: 0.8601700865440773, bias: -0.46376687497461755, loss: 0.5876944752442369\n",
            "Epochs: 1000, w1: 0.973975992794198, w2: 0.8600019032500585, bias: -0.46496641226642754, loss: 0.587546139773684\n",
            "Epochs: 1000, w1: 0.9740807374816227, w2: 0.8598356381330596, bias: -0.46616311385886866, loss: 0.5873985286158253\n",
            "Epochs: 1000, w1: 0.9741865850092417, w2: 0.8596712845931793, bias: -0.4673569889561362, loss: 0.5872516368212712\n",
            "Epochs: 1000, w1: 0.9742935317238589, w2: 0.8595088360433599, bias: -0.46854804674138195, loss: 0.5871054594716028\n",
            "Epochs: 1000, w1: 0.9744015739802545, w2: 0.8593482859094477, bias: -0.4697362963766662, loss: 0.5869599916792262\n",
            "Epochs: 1000, w1: 0.9745107081412081, w2: 0.8591896276302522, bias: -0.4709217470029112, loss: 0.5868152285872272\n",
            "Epochs: 1000, w1: 0.9746209305775209, w2: 0.8590328546576049, bias: -0.4721044077398553, loss: 0.5866711653692245\n",
            "Epochs: 1000, w1: 0.9747322376680377, w2: 0.8588779604564165, bias: -0.4732842876860089, loss: 0.5865277972292244\n",
            "Epochs: 1000, w1: 0.9748446257996687, w2: 0.858724938504733, bias: -0.4744613959186111, loss: 0.5863851194014758\n",
            "Epochs: 1000, w1: 0.9749580913674096, w2: 0.8585737822937911, bias: -0.4756357414935875, loss: 0.586243127150322\n",
            "Epochs: 1000, w1: 0.9750726307743631, w2: 0.8584244853280728, bias: -0.4768073334455095, loss: 0.5861018157700584\n",
            "Epochs: 1000, w1: 0.9751882404317582, w2: 0.8582770411253584, bias: -0.47797618078755433, loss: 0.5859611805847842\n",
            "Epochs: 1000, w1: 0.9753049167589701, w2: 0.8581314432167793, bias: -0.47914229251146623, loss: 0.5858212169482583\n",
            "Epochs: 1000, w1: 0.9754226561835391, w2: 0.8579876851468686, bias: -0.480305677587519, loss: 0.5856819202437538\n",
            "Epochs: 1000, w1: 0.9755414551411891, w2: 0.8578457604736126, bias: -0.48146634496447954, loss: 0.5855432858839125\n",
            "Epochs: 1000, w1: 0.9756613100758461, w2: 0.8577056627684994, bias: -0.48262430356957214, loss: 0.5854053093106006\n",
            "Epochs: 1000, w1: 0.9757822174396559, w2: 0.8575673856165676, bias: -0.48377956230844443, loss: 0.5852679859947624\n",
            "Epochs: 1000, w1: 0.9759041736930009, w2: 0.8574309226164544, bias: -0.4849321300651339, loss: 0.5851313114362771\n",
            "Epochs: 1000, w1: 0.9760271753045173, w2: 0.8572962673804412, bias: -0.48608201570203574, loss: 0.5849952811638128\n",
            "Epochs: 1000, w1: 0.9761512187511115, w2: 0.8571634135345003, bias: -0.4872292280598715, loss: 0.5848598907346831\n",
            "Epochs: 1000, w1: 0.976276300517976, w2: 0.8570323547183394, bias: -0.48837377595765913, loss: 0.5847251357347024\n",
            "Epochs: 1000, w1: 0.9764024170986045, w2: 0.856903084585445, bias: -0.48951566819268366, loss: 0.5845910117780414\n",
            "Epochs: 1000, w1: 0.9765295649948077, w2: 0.8567755968031259, bias: -0.49065491354046925, loss: 0.5844575145070837\n",
            "Epochs: 1000, w1: 0.9766577407167272, w2: 0.8566498850525552, bias: -0.49179152075475185, loss: 0.5843246395922828\n",
            "Epochs: 1000, w1: 0.9767869407828502, w2: 0.8565259430288114, bias: -0.4929254985674533, loss: 0.5841923827320166\n",
            "Epochs: 1000, w1: 0.9769171617200233, w2: 0.8564037644409185, bias: -0.49405685568865615, loss: 0.5840607396524461\n",
            "Epochs: 1000, w1: 0.9770484000634655, w2: 0.8562833430118857, bias: -0.49518560080657925, loss: 0.5839297061073716\n",
            "Epochs: 1000, w1: 0.9771806523567816, w2: 0.8561646724787458, bias: -0.49631174258755495, loss: 0.5837992778780898\n",
            "Epochs: 1000, w1: 0.9773139151519749, w2: 0.8560477465925932, bias: -0.49743528967600664, loss: 0.5836694507732516\n",
            "Epochs: 1000, w1: 0.9774481850094584, w2: 0.8559325591186201, bias: -0.49855625069442755, loss: 0.5835402206287194\n",
            "Epochs: 1000, w1: 0.9775834584980679, w2: 0.8558191038361532, bias: -0.49967463424336034, loss: 0.5834115833074245\n",
            "Epochs: 1000, w1: 0.9777197321950725, w2: 0.8557073745386884, bias: -0.5007904489013777, loss: 0.5832835346992273\n",
            "Epochs: 1000, w1: 0.9778570026861857, w2: 0.8555973650339254, bias: -0.5019037032250641, loss: 0.5831560707207738\n",
            "Epochs: 1000, w1: 0.9779952665655763, w2: 0.855489069143801, bias: -0.5030144057489977, loss: 0.583029187315355\n",
            "Epochs: 1000, w1: 0.9781345204358785, w2: 0.8553824807045217, bias: -0.5041225649857343, loss: 0.5829028804527661\n",
            "Epochs: 1000, w1: 0.9782747609082013, w2: 0.8552775935665962, bias: -0.5052281894257912, loss: 0.5827771461291658\n",
            "Epochs: 1000, w1: 0.9784159846021386, w2: 0.8551744015948656, bias: -0.5063312875376323, loss: 0.5826519803669356\n",
            "Epochs: 1000, w1: 0.9785581881457779, w2: 0.8550728986685343, bias: -0.5074318677676545, loss: 0.5825273792145402\n",
            "Epochs: 1000, w1: 0.978701368175709, w2: 0.8549730786811993, bias: -0.5085299385401738, loss: 0.5824033387463874\n",
            "Epochs: 1000, w1: 0.9788455213370325, w2: 0.8548749355408788, bias: -0.5096255082574138, loss: 0.5822798550626889\n",
            "Epochs: 1000, w1: 0.9789906442833677, w2: 0.8547784631700404, bias: -0.5107185852994941, loss: 0.5821569242893212\n",
            "Epochs: 1000, w1: 0.9791367336768602, w2: 0.854683655505628, bias: -0.5118091780244193, loss: 0.5820345425776863\n",
            "Epochs: 1000, w1: 0.979283786188189, w2: 0.8545905064990883, bias: -0.5128972947680697, loss: 0.581912706104574\n",
            "Epochs: 1000, w1: 0.9794317984965739, w2: 0.8544990101163967, bias: -0.5139829438441922, loss: 0.5817914110720233\n",
            "Epochs: 1000, w1: 0.9795807672897815, w2: 0.854409160338082, bias: -0.5150661335443922, loss: 0.5816706537071842\n",
            "Epochs: 1000, w1: 0.9797306892641318, w2: 0.8543209511592504, bias: -0.5161468721381265, loss: 0.5815504302621818\n",
            "Epochs: 1000, w1: 0.9798815611245036, w2: 0.8542343765896093, bias: -0.5172251678726963, loss: 0.5814307370139776\n",
            "Epochs: 1000, w1: 0.9800333795843408, w2: 0.8541494306534897, bias: -0.5183010289732424, loss: 0.5813115702642339\n",
            "Epochs: 1000, w1: 0.9801861413656566, w2: 0.8540661073898685, bias: -0.5193744636427392, loss: 0.5811929263391765\n",
            "Epochs: 1000, w1: 0.9803398431990393, w2: 0.8539844008523897, bias: -0.5204454800619914, loss: 0.5810748015894596\n",
            "Epochs: 1000, w1: 0.9804944818236563, w2: 0.8539043051093846, bias: -0.5215140863896304, loss: 0.58095719239003\n",
            "Epochs: 1000, w1: 0.9806500539872584, w2: 0.8538258142438926, bias: -0.5225802907621113, loss: 0.5808400951399915\n",
            "Epochs: 1000, w1: 0.9808065564461836, w2: 0.8537489223536793, bias: -0.5236441012937118, loss: 0.5807235062624705\n",
            "Epochs: 1000, w1: 0.980963985965361, w2: 0.8536736235512556, bias: -0.5247055260765301, loss: 0.5806074222044812\n",
            "Epochs: 1000, w1: 0.9811223393183138, w2: 0.8535999119638957, bias: -0.5257645731804856, loss: 0.5804918394367925\n",
            "Epochs: 1000, w1: 0.981281613287162, w2: 0.8535277817336538, bias: -0.5268212506533184, loss: 0.5803767544537926\n",
            "Epochs: 1000, w1: 0.9814418046626255, w2: 0.853457227017381, bias: -0.5278755665205908, loss: 0.5802621637733575\n",
            "Epochs: 1000, w1: 0.9816029102440261, w2: 0.8533882419867407, bias: -0.5289275287856888, loss: 0.5801480639367174\n",
            "Epochs: 1000, w1: 0.9817649268392897, w2: 0.8533208208282241, bias: -0.529977145429825, loss: 0.5800344515083243\n",
            "Epochs: 1000, w1: 0.981927851264948, w2: 0.853254957743165, bias: -0.5310244244120413, loss: 0.5799213230757201\n",
            "Epochs: 1000, w1: 0.9820916803461395, w2: 0.8531906469477528, bias: -0.5320693736692131, loss: 0.5798086752494049\n",
            "Epochs: 1000, w1: 0.9822564109166113, w2: 0.8531278826730468, bias: -0.5331120011160536, loss: 0.5796965046627061\n",
            "Epochs: 1000, w1: 0.9824220398187197, w2: 0.8530666591649883, bias: -0.5341523146451193, loss: 0.5795848079716475\n",
            "Epochs: 1000, w1: 0.9825885639034302, w2: 0.8530069706844123, bias: -0.5351903221268155, loss: 0.5794735818548182\n",
            "Epochs: 1000, w1: 0.9827559800303187, w2: 0.8529488115070598, bias: -0.5362260314094034, loss: 0.579362823013245\n",
            "Epochs: 1000, w1: 0.9829242850675709, w2: 0.8528921759235877, bias: -0.5372594503190067, loss: 0.5792525281702604\n",
            "Epochs: 1000, w1: 0.9830934758919819, w2: 0.8528370582395796, bias: -0.5382905866596197, loss: 0.5791426940713748\n",
            "Epochs: 1000, w1: 0.9832635493889561, w2: 0.852783452775555, bias: -0.5393194482131161, loss: 0.5790333174841481\n",
            "Epochs: 1000, w1: 0.983434502452506, w2: 0.8527313538669787, bias: -0.5403460427392572, loss: 0.578924395198061\n",
            "Epochs: 1000, w1: 0.983606331985251, w2: 0.852680755864269, bias: -0.5413703779757029, loss: 0.5788159240243881\n",
            "Epochs: 1000, w1: 0.9837790348984167, w2: 0.8526316531328051, bias: -0.5423924616380207, loss: 0.57870790079607\n",
            "Epochs: 1000, w1: 0.9839526081118323, w2: 0.8525840400529353, bias: -0.5434123014196977, loss: 0.5786003223675865\n",
            "Epochs: 1000, w1: 0.9841270485539294, w2: 0.8525379110199831, bias: -0.5444299049921514, loss: 0.5784931856148309\n",
            "Epochs: 1000, w1: 0.9843023531617396, w2: 0.8524932604442533, bias: -0.5454452800047425, loss: 0.578386487434984\n",
            "Epochs: 1000, w1: 0.9844785188808921, w2: 0.8524500827510381, bias: -0.546458434084787, loss: 0.5782802247463883\n",
            "Epochs: 1000, w1: 0.984655542665611, w2: 0.8524083723806214, bias: -0.54746937483757, loss: 0.5781743944884236\n",
            "Epochs: 1000, w1: 0.9848334214787122, w2: 0.852368123788284, bias: -0.548478109846359, loss: 0.5780689936213821\n",
            "Epochs: 1000, w1: 0.9850121522916011, w2: 0.8523293314443071, bias: -0.549484646672419, loss: 0.5779640191263445\n",
            "Epochs: 1000, w1: 0.9851917320842679, w2: 0.852291989833976, bias: -0.5504889928550272, loss: 0.577859468005057\n",
            "Epochs: 1000, w1: 0.9853721578452851, w2: 0.852256093457583, bias: -0.5514911559114881, loss: 0.577755337279808\n",
            "Epochs: 1000, w1: 0.9855534265718028, w2: 0.8522216368304295, bias: -0.5524911433371505, loss: 0.5776516239933046\n",
            "Epochs: 1000, w1: 0.985735535269545, w2: 0.8521886144828281, bias: -0.5534889626054236, loss: 0.5775483252085527\n",
            "Epochs: 1000, w1: 0.9859184809528055, w2: 0.8521570209601042, bias: -0.5544846211677937, loss: 0.5774454380087328\n",
            "Epochs: 1000, w1: 0.9861022606444427, w2: 0.8521268508225961, bias: -0.5554781264538431, loss: 0.5773429594970809\n",
            "Epochs: 1000, w1: 0.9862868713758751, w2: 0.8520980986456564, bias: -0.5564694858712671, loss: 0.5772408867967669\n",
            "Epochs: 1000, w1: 0.9864723101870764, w2: 0.8520707590196511, bias: -0.5574587068058934, loss: 0.5771392170507744\n",
            "Epochs: 1000, w1: 0.9866585741265699, w2: 0.8520448265499592, bias: -0.5584457966217011, loss: 0.5770379474217818\n",
            "Epochs: 1000, w1: 0.9868456602514236, w2: 0.8520202958569716, bias: -0.5594307626608405, loss: 0.5769370750920424\n",
            "Epochs: 1000, w1: 0.987033565627244, w2: 0.8519971615760897, bias: -0.560413612243653, loss: 0.5768365972632655\n",
            "Epochs: 1000, w1: 0.9872222873281704, w2: 0.8519754183577232, bias: -0.5613943526686926, loss: 0.5767365111564994\n",
            "Epochs: 1000, w1: 0.9874118224368688, w2: 0.8519550608672872, bias: -0.5623729912127461, loss: 0.5766368140120124\n",
            "Epochs: 1000, w1: 0.9876021680445254, w2: 0.8519360837852002, bias: -0.5633495351308553, loss: 0.5765375030891761\n",
            "Epochs: 1000, w1: 0.9877933212508405, w2: 0.85191848180688, bias: -0.5643239916563391, loss: 0.5764385756663488\n",
            "Epochs: 1000, w1: 0.9879852791640213, w2: 0.8519022496427396, bias: -0.5652963680008158, loss: 0.5763400290407594\n",
            "Epochs: 1000, w1: 0.9881780389007755, w2: 0.8518873820181835, bias: -0.5662666713542268, loss: 0.5762418605283913\n",
            "Epochs: 1000, w1: 0.9883715975863034, w2: 0.8518738736736026, bias: -0.5672349088848593, loss: 0.5761440674638669\n",
            "Epochs: 1000, w1: 0.9885659523542915, w2: 0.8518617193643689, bias: -0.5682010877393705, loss: 0.5760466472003337\n",
            "Epochs: 1000, w1: 0.988761100346904, w2: 0.8518509138608304, bias: -0.5691652150428124, loss: 0.5759495971093499\n",
            "Epochs: 1000, w1: 0.9889570387147762, w2: 0.8518414519483045, bias: -0.5701272978986559, loss: 0.5758529145807697\n",
            "Epochs: 1000, w1: 0.9891537646170059, w2: 0.8518333284270717, bias: -0.5710873433888166, loss: 0.5757565970226315\n",
            "Epochs: 1000, w1: 0.9893512752211451, w2: 0.8518265381123689, bias: -0.5720453585736802, loss: 0.5756606418610439\n",
            "Epochs: 1000, w1: 0.9895495677031924, w2: 0.8518210758343817, bias: -0.5730013504921286, loss: 0.5755650465400742\n",
            "Epochs: 1000, w1: 0.9897486392475843, w2: 0.8518169364382373, bias: -0.5739553261615664, loss: 0.5754698085216371\n",
            "Epochs: 1000, w1: 0.9899484870471863, w2: 0.8518141147839958, bias: -0.5749072925779477, loss: 0.575374925285382\n",
            "Epochs: 1000, w1: 0.9901491083032846, w2: 0.8518126057466421, bias: -0.5758572567158035, loss: 0.5752803943285835\n",
            "Epochs: 1000, w1: 0.9903505002255767, w2: 0.8518124042160768, bias: -0.5768052255282692, loss: 0.5751862131660314\n",
            "Epochs: 1000, w1: 0.9905526600321624, w2: 0.8518135050971074, bias: -0.577751205947113, loss: 0.5750923793299197\n",
            "Epochs: 1000, w1: 0.9907555849495344, w2: 0.8518159033094378, bias: -0.5786952048827642, loss: 0.5749988903697385\n",
            "Epochs: 1000, w1: 0.9909592722125693, w2: 0.8518195937876589, bias: -0.5796372292243415, loss: 0.5749057438521654\n",
            "Epochs: 1000, w1: 0.9911637190645172, w2: 0.8518245714812382, bias: -0.5805772858396828, loss: 0.5748129373609561\n",
            "Epochs: 1000, w1: 0.9913689227569922, w2: 0.8518308313545089, bias: -0.5815153815753749, loss: 0.574720468496838\n",
            "Epochs: 1000, w1: 0.9915748805499628, w2: 0.8518383683866585, bias: -0.5824515232567827, loss: 0.5746283348774028\n",
            "Epochs: 1000, w1: 0.9917815897117412, w2: 0.8518471775717179, bias: -0.5833857176880801, loss: 0.574536534136999\n",
            "Epochs: 1000, w1: 0.9919890475189734, w2: 0.851857253918549, bias: -0.5843179716522803, loss: 0.5744450639266268\n",
            "Epochs: 1000, w1: 0.9921972512566286, w2: 0.8518685924508329, bias: -0.5852482919112668, loss: 0.5743539219138313\n",
            "Epochs: 1000, w1: 0.9924061982179885, w2: 0.851881188207057, bias: -0.5861766852058249, loss: 0.5742631057825991\n",
            "Epochs: 1000, w1: 0.9926158857046367, w2: 0.8518950362405026, bias: -0.587103158255673, loss: 0.5741726132332516\n",
            "Epochs: 1000, w1: 0.9928263110264478, w2: 0.8519101316192311, bias: -0.5880277177594951, loss: 0.5740824419823423\n",
            "Epochs: 1000, w1: 0.9930374715015765, w2: 0.8519264694260712, bias: -0.5889503703949724, loss: 0.5739925897625526\n",
            "Epochs: 1000, w1: 0.9932493644564461, w2: 0.8519440447586041, bias: -0.5898711228188166, loss: 0.5739030543225888\n",
            "Epochs: 1000, w1: 0.9934619872257372, w2: 0.8519628527291502, bias: -0.5907899816668022, loss: 0.5738138334270796\n",
            "Epochs: 1000, w1: 0.9936753371523767, w2: 0.8519828884647539, bias: -0.5917069535538003, loss: 0.573724924856474\n",
            "Epochs: 1000, w1: 0.9938894115875255, w2: 0.8520041471071693, bias: -0.5926220450738119, loss: 0.5736363264069392\n",
            "Epochs: 1000, w1: 0.9941042078905674, w2: 0.8520266238128446, bias: -0.5935352628000016, loss: 0.5735480358902598\n",
            "Epochs: 1000, w1: 0.9943197234290967, w2: 0.8520503137529069, bias: -0.594446613284732, loss: 0.5734600511337381\n",
            "Epochs: 1000, w1: 0.9945359555789066, w2: 0.8520752121131464, bias: -0.5953561030595982, loss: 0.5733723699800923\n",
            "Epochs: 1000, w1: 0.9947529017239769, w2: 0.8521013140940004, bias: -0.596263738635462, loss: 0.5732849902873582\n",
            "Epochs: 1000, w1: 0.9949705592564617, w2: 0.8521286149105367, bias: -0.5971695265024876, loss: 0.5731979099287897\n",
            "Epochs: 1000, w1: 0.9951889255766769, w2: 0.8521571097924374, bias: -0.5980734731301763, loss: 0.5731111267927602\n",
            "Epochs: 1000, w1: 0.9954079980930881, w2: 0.8521867939839816, bias: -0.5989755849674026, loss: 0.5730246387826644\n",
            "Epochs: 1000, w1: 0.9956277742222975, w2: 0.8522176627440281, bias: -0.5998758684424494, loss: 0.5729384438168214\n",
            "Epochs: 1000, w1: 0.9958482513890314, w2: 0.8522497113459985, bias: -0.6007743299630448, loss: 0.5728525398283766\n",
            "Epochs: 1000, w1: 0.9960694270261272, w2: 0.8522829350778588, bias: -0.6016709759163977, loss: 0.5727669247652055\n",
            "Epochs: 1000, w1: 0.9962912985745204, w2: 0.8523173292421016, bias: -0.6025658126692351, loss: 0.5726815965898187\n",
            "Epochs: 1000, w1: 0.9965138634832317, w2: 0.8523528891557278, bias: -0.6034588465678385, loss: 0.5725965532792643\n",
            "Epochs: 1000, w1: 0.9967371192093535, w2: 0.8523896101502283, bias: -0.6043500839380812, loss: 0.5725117928250345\n",
            "Epochs: 1000, w1: 0.9969610632180367, w2: 0.8524274875715644, bias: -0.6052395310854656, loss: 0.5724273132329704\n",
            "Epochs: 1000, w1: 0.9971856929824773, w2: 0.8524665167801495, bias: -0.6061271942951607, loss: 0.5723431125231676\n",
            "Epochs: 1000, w1: 0.9974110059839026, w2: 0.8525066931508294, bias: -0.6070130798320402, loss: 0.5722591887298832\n",
            "Epochs: 1000, w1: 0.9976369997115582, w2: 0.8525480120728627, bias: -0.6078971939407203, loss: 0.5721755399014427\n",
            "Epochs: 1000, w1: 0.9978636716626931, w2: 0.8525904689499011, bias: -0.608779542845598, loss: 0.5720921641001466\n",
            "Epochs: 1000, w1: 0.9980910193425468, w2: 0.8526340591999692, bias: -0.6096601327508897, loss: 0.5720090594021793\n",
            "Epochs: 1000, w1: 0.9983190402643353, w2: 0.852678778255444, bias: -0.6105389698406699, loss: 0.5719262238975167\n",
            "Epochs: 1000, w1: 0.9985477319492363, w2: 0.852724621563035, bias: -0.6114160602789102, loss: 0.5718436556898356\n",
            "Epochs: 1000, w1: 0.9987770919263756, w2: 0.8527715845837623, bias: -0.6122914102095182, loss: 0.5717613528964232\n",
            "Epochs: 1000, w1: 0.9990071177328129, w2: 0.852819662792937, bias: -0.6131650257563772, loss: 0.5716793136480856\n",
            "Epochs: 1000, w1: 0.9992378069135271, w2: 0.8528688516801385, bias: -0.6140369130233855, loss: 0.5715975360890602\n",
            "Epochs: 1000, w1: 0.9994691570214022, w2: 0.852919146749194, bias: -0.6149070780944962, loss: 0.5715160183769251\n",
            "Epochs: 1000, w1: 0.999701165617212, w2: 0.8529705435181566, bias: -0.6157755270337574, loss: 0.5714347586825107\n",
            "Epochs: 1000, w1: 0.9999338302696068, w2: 0.8530230375192831, bias: -0.6166422658853519, loss: 0.571353755189812\n",
            "Epochs: 1000, w1: 1.0001671485550974, w2: 0.8530766242990123, bias: -0.6175073006736378, loss: 0.5712730060958998\n",
            "Epochs: 1000, w1: 1.000401118058041, w2: 0.8531312994179424, bias: -0.6183706374031893, loss: 0.5711925096108349\n",
            "Epochs: 1000, w1: 1.000635736370626, w2: 0.8531870584508086, bias: -0.6192322820588368, loss: 0.5711122639575801\n",
            "Epochs: 1000, w1: 1.000871001092857, w2: 0.8532438969864601, bias: -0.6200922406057082, loss: 0.5710322673719144\n",
            "Epochs: 1000, w1: 1.0011069098325402, w2: 0.8533018106278376, bias: -0.6209505189892698, loss: 0.5709525181023479\n",
            "Epochs: 1000, w1: 1.0013434602052678, w2: 0.8533607949919498, bias: -0.6218071231353676, loss: 0.5708730144100348\n",
            "Epochs: 1000, w1: 1.0015806498344026, w2: 0.8534208457098503, bias: -0.6226620589502686, loss: 0.5707937545686903\n",
            "Epochs: 1000, w1: 1.0018184763510636, w2: 0.853481958426614, bias: -0.6235153323207024, loss: 0.5707147368645052\n",
            "Epochs: 1000, w1: 1.0020569373941093, w2: 0.8535441288013134, bias: -0.6243669491139031, loss: 0.5706359595960625\n",
            "Epochs: 1000, w1: 1.0022960306101236, w2: 0.8536073525069945, bias: -0.6252169151776507, loss: 0.5705574210742536\n",
            "Epochs: 1000, w1: 1.0025357536533992, w2: 0.8536716252306533, bias: -0.6260652363403133, loss: 0.5704791196221953\n",
            "Epochs: 1000, w1: 1.002776104185923, w2: 0.853736942673211, bias: -0.6269119184108899, loss: 0.570401053575148\n",
            "Epochs: 1000, w1: 1.003017079877359, w2: 0.8538033005494897, bias: -0.6277569671790517, loss: 0.5703232212804332\n",
            "Epochs: 1000, w1: 1.0032586784050341, w2: 0.8538706945881881, bias: -0.6286003884151854, loss: 0.5702456210973513\n",
            "Epochs: 1000, w1: 1.0035008974539217, w2: 0.8539391205318564, bias: -0.6294421878704352, loss: 0.5701682513971025\n",
            "Epochs: 1000, w1: 1.0037437347166256, w2: 0.8540085741368714, bias: -0.6302823712767458, loss: 0.5700911105627032\n",
            "Epochs: 1000, w1: 1.003987187893364, w2: 0.8540790511734117, bias: -0.6311209443469056, loss: 0.570014196988909\n",
            "Epochs: 1000, w1: 1.0042312546919538, w2: 0.8541505474254321, bias: -0.6319579127745891, loss: 0.5699375090821327\n",
            "Epochs: 1000, w1: 1.004475932827795, w2: 0.8542230586906383, bias: -0.6327932822344005, loss: 0.5698610452603661\n",
            "Epochs: 1000, w1: 1.0047212200238533, w2: 0.8542965807804614, bias: -0.6336270583819165, loss: 0.5697848039531008\n",
            "Epochs: 1000, w1: 1.0049671140106453, w2: 0.8543711095200323, bias: -0.6344592468537301, loss: 0.5697087836012508\n",
            "Epochs: 1000, w1: 1.005213612526221, w2: 0.8544466407481552, bias: -0.6352898532674942, loss: 0.569632982657073\n",
            "Epochs: 1000, w1: 1.0054607133161484, w2: 0.8545231703172826, bias: -0.6361188832219646, loss: 0.5695573995840912\n",
            "Epochs: 1000, w1: 1.005708414133497, w2: 0.8546006940934883, bias: -0.6369463422970444, loss: 0.5694820328570187\n",
            "Epochs: 1000, w1: 1.0059567127388211, w2: 0.8546792079564411, bias: -0.6377722360538272, loss: 0.5694068809616812\n",
            "Epochs: 1000, w1: 1.0062056069001433, w2: 0.8547587077993792, bias: -0.6385965700346417, loss: 0.5693319423949421\n",
            "Epochs: 1000, w1: 1.0064550943929382, w2: 0.8548391895290827, bias: -0.6394193497630951, loss: 0.5692572156646253\n",
            "Epochs: 1000, w1: 1.006705173000116, w2: 0.854920649065847, bias: -0.640240580744118, loss: 0.569182699289441\n",
            "Epochs: 1000, w1: 1.0069558405120054, w2: 0.8550030823434566, bias: -0.641060268464008, loss: 0.569108391798911\n",
            "Epochs: 1000, w1: 1.0072070947263372, w2: 0.8550864853091574, bias: -0.6418784183904742, loss: 0.5690342917332939\n",
            "Epochs: 1000, w1: 1.0074589334482276, w2: 0.85517085392363, bias: -0.6426950359726818, loss: 0.5689603976435115\n",
            "Epochs: 1000, w1: 1.0077113544901615, w2: 0.8552561841609624, bias: -0.6435101266412967, loss: 0.5688867080910754\n",
            "Epochs: 1000, w1: 1.0079643556719755, w2: 0.8553424720086223, bias: -0.6443236958085297, loss: 0.5688132216480144\n",
            "Epochs: 1000, w1: 1.008217934820841, w2: 0.8554297134674304, bias: -0.6451357488681815, loss: 0.5687399368968012\n",
            "Epochs: 1000, w1: 1.0084720897712476, w2: 0.8555179045515316, bias: -0.6459462911956876, loss: 0.5686668524302809\n",
            "Epochs: 1000, w1: 1.0087268183649858, w2: 0.8556070412883688, bias: -0.646755328148163, loss: 0.568593966851599\n",
            "Epochs: 1000, w1: 1.0089821184511303, w2: 0.8556971197186538, bias: -0.6475628650644469, loss: 0.5685212787741306\n",
            "Epochs: 1000, w1: 1.0092379878860227, w2: 0.8557881358963401, bias: -0.6483689072651484, loss: 0.5684487868214089\n",
            "Epochs: 1000, w1: 1.0094944245332549, w2: 0.8558800858885943, bias: -0.6491734600526907, loss: 0.5683764896270552\n",
            "Epochs: 1000, w1: 1.0097514262636513, w2: 0.8559729657757688, bias: -0.6499765287113571, loss: 0.5683043858347099\n",
            "Epochs: 1000, w1: 1.0100089909552525, w2: 0.8560667716513725, bias: -0.6507781185073358, loss: 0.568232474097961\n",
            "Epochs: 1000, w1: 1.0102671164932975, w2: 0.8561614996220432, bias: -0.6515782346887651, loss: 0.5681607530802761\n",
            "Epochs: 1000, w1: 1.0105258007702065, w2: 0.8562571458075192, bias: -0.6523768824857789, loss: 0.5680892214549345\n",
            "Epochs: 1000, w1: 1.010785041685564, w2: 0.85635370634061, bias: -0.6531740671105521, loss: 0.5680178779049571\n",
            "Epochs: 1000, w1: 1.0110448371461014, w2: 0.8564511773671686, bias: -0.6539697937573465, loss: 0.5679467211230401\n",
            "Epochs: 1000, w1: 1.0113051850656796, w2: 0.8565495550460619, bias: -0.6547640676025555, loss: 0.567875749811487\n",
            "Epochs: 1000, w1: 1.0115660833652715, w2: 0.8566488355491425, bias: -0.6555568938047501, loss: 0.5678049626821412\n",
            "Epochs: 1000, w1: 1.0118275299729453, w2: 0.8567490150612196, bias: -0.6563482775047248, loss: 0.56773435845632\n",
            "Epochs: 1000, w1: 1.0120895228238462, w2: 0.8568500897800299, bias: -0.6571382238255429, loss: 0.5676639358647484\n",
            "Epochs: 1000, w1: 1.0123520598601798, w2: 0.8569520559162086, bias: -0.6579267378725824, loss: 0.5675936936474926\n",
            "Epochs: 1000, w1: 1.012615139031194, w2: 0.8570549096932604, bias: -0.6587138247335818, loss: 0.5675236305538953\n",
            "Epochs: 1000, w1: 1.0128787582931615, w2: 0.8571586473475297, bias: -0.6594994894786856, loss: 0.5674537453425107\n",
            "Epochs: 1000, w1: 1.0131429156093634, w2: 0.8572632651281719, bias: -0.6602837371604908, loss: 0.5673840367810397\n",
            "Epochs: 1000, w1: 1.01340760895007, w2: 0.8573687592971238, bias: -0.6610665728140922, loss: 0.5673145036462656\n",
            "Epochs: 1000, w1: 1.0136728362925247, w2: 0.8574751261290738, bias: -0.6618480014571286, loss: 0.56724514472399\n",
            "Epochs: 1000, w1: 1.0139385956209255, w2: 0.857582361911433, bias: -0.6626280280898287, loss: 0.5671759588089708\n",
            "Epochs: 1000, w1: 1.0142048849264078, w2: 0.8576904629443048, bias: -0.6634066576950571, loss: 0.5671069447048583\n",
            "Epochs: 1000, w1: 1.0144717022070266, w2: 0.8577994255404559, bias: -0.6641838952383605, loss: 0.5670381012241318\n",
            "Epochs: 1000, w1: 1.0147390454677394, w2: 0.857909246025286, bias: -0.6649597456680134, loss: 0.5669694271880388\n",
            "Epochs: 1000, w1: 1.0150069127203876, w2: 0.8580199207367984, bias: -0.6657342139150646, loss: 0.5669009214265325\n",
            "Epochs: 1000, w1: 1.0152753019836795, w2: 0.85813144602557, bias: -0.666507304893383, loss: 0.5668325827782108\n",
            "Epochs: 1000, w1: 1.0155442112831727, w2: 0.8582438182547212, bias: -0.6672790234997038, loss: 0.5667644100902547\n",
            "Epochs: 1000, w1: 1.015813638651256, w2: 0.8583570337998858, bias: -0.6680493746136749, loss: 0.5666964022183681\n",
            "Epochs: 1000, w1: 1.0160835821271315, w2: 0.8584710890491813, bias: -0.6688183630979025, loss: 0.5666285580267171\n",
            "Epochs: 1000, w1: 1.0163540397567974, w2: 0.8585859804031788, bias: -0.6695859937979981, loss: 0.5665608763878708\n",
            "Epochs: 1000, w1: 1.0166250095930303, w2: 0.8587017042748722, bias: -0.6703522715426239, loss: 0.566493356182741\n",
            "Epochs: 1000, w1: 1.0168964896953667, w2: 0.8588182570896487, bias: -0.6711172011435395, loss: 0.5664259963005239\n",
            "Epochs: 1000, w1: 1.0171684781300863, w2: 0.858935635285258, bias: -0.6718807873956479, loss: 0.5663587956386407\n",
            "Epochs: 1000, w1: 1.0174409729701928, w2: 0.8590538353117824, bias: -0.6726430350770422, loss: 0.5662917531026795\n",
            "Epochs: 1000, w1: 1.0177139722953974, w2: 0.8591728536316059, bias: -0.6734039489490509, loss: 0.5662248676063376\n",
            "Epochs: 1000, w1: 1.0179874741921002, w2: 0.8592926867193844, bias: -0.6741635337562851, loss: 0.5661581380713631\n",
            "Epochs: 1000, w1: 1.018261476753373, w2: 0.8594133310620148, bias: -0.6749217942266844, loss: 0.5660915634274982\n",
            "Epochs: 1000, w1: 1.0185359780789411, w2: 0.8595347831586044, bias: -0.675678735071563, loss: 0.5660251426124222\n",
            "Epochs: 1000, w1: 1.018810976275165, w2: 0.8596570395204409, bias: -0.6764343609856559, loss: 0.5659588745716954\n",
            "Epochs: 1000, w1: 1.0190864694550232, w2: 0.8597800966709611, bias: -0.6771886766471659, loss: 0.5658927582587019\n",
            "Epochs: 1000, w1: 1.019362455738095, w2: 0.8599039511457207, bias: -0.6779416867178087, loss: 0.5658267926345949\n",
            "Epochs: 1000, w1: 1.0196389332505404, w2: 0.8600285994923638, bias: -0.6786933958428603, loss: 0.5657609766682407\n",
            "Epochs: 1000, w1: 1.019915900125085, w2: 0.8601540382705914, bias: -0.6794438086512021, loss: 0.5656953093361633\n",
            "Epochs: 1000, w1: 1.020193354501, w2: 0.8602802640521319, bias: -0.6801929297553684, loss: 0.5656297896224904\n",
            "Epochs: 1000, w1: 1.0204712945240852, w2: 0.8604072734207089, bias: -0.6809407637515914, loss: 0.5655644165188991\n",
            "Epochs: 1000, w1: 1.0207497183466514, w2: 0.8605350629720117, bias: -0.6816873152198484, loss: 0.5654991890245606\n",
            "Epochs: 1000, w1: 1.021028624127502, w2: 0.8606636293136636, bias: -0.6824325887239073, loss: 0.5654341061460888\n",
            "Epochs: 1000, w1: 1.021308010031915, w2: 0.8607929690651914, bias: -0.6831765888113733, loss: 0.5653691668974838\n",
            "Epochs: 1000, w1: 1.0215878742316258, w2: 0.8609230788579945, bias: -0.6839193200137349, loss: 0.5653043703000823\n",
            "Epochs: 1000, w1: 1.0218682149048088, w2: 0.8610539553353138, bias: -0.6846607868464097, loss: 0.5652397153825025\n",
            "Epochs: 1000, w1: 1.0221490302360599, w2: 0.861185595152201, bias: -0.6854009938087913, loss: 0.5651752011805935\n",
            "Epochs: 1000, w1: 1.0224303184163777, w2: 0.8613179949754877, bias: -0.6861399453842947, loss: 0.565110826737382\n",
            "Epochs: 1000, w1: 1.0227120776431469, w2: 0.8614511514837538, bias: -0.6868776460404029, loss: 0.5650465911030215\n",
            "Epochs: 1000, w1: 1.0229943061201194, w2: 0.8615850613672975, bias: -0.6876141002287127, loss: 0.5649824933347409\n",
            "Epochs: 1000, w1: 1.0232770020573974, w2: 0.8617197213281034, bias: -0.688349312384981, loss: 0.5649185324967937\n",
            "Epochs: 1000, w1: 1.0235601636714142, w2: 0.8618551280798119, bias: -0.6890832869291705, loss: 0.564854707660407\n",
            "Epochs: 1000, w1: 1.0238437891849177, w2: 0.8619912783476882, bias: -0.6898160282654963, loss: 0.5647910179037319\n",
            "Epochs: 1000, w1: 1.0241278768269517, w2: 0.8621281688685908, bias: -0.6905475407824709, loss: 0.5647274623117925\n",
            "Epochs: 1000, w1: 1.0244124248328383, w2: 0.8622657963909409, bias: -0.6912778288529514, loss: 0.5646640399764377\n",
            "Epochs: 1000, w1: 1.0246974314441601, w2: 0.8624041576746913, bias: -0.6920068968341844, loss: 0.5646007499962908\n",
            "Epochs: 1000, w1: 1.024982894908742, w2: 0.8625432494912946, bias: -0.6927347490678524, loss: 0.5645375914767011\n",
            "Epochs: 1000, w1: 1.0252688134806338, w2: 0.8626830686236732, bias: -0.6934613898801195, loss: 0.5644745635296956\n",
            "Epochs: 1000, w1: 1.0255551854200922, w2: 0.8628236118661872, bias: -0.6941868235816775, loss: 0.5644116652739298\n",
            "Epochs: 1000, w1: 1.025842008993563, w2: 0.8629648760246037, bias: -0.6949110544677912, loss: 0.5643488958346403\n",
            "Epochs: 1000, w1: 1.026129282473663, w2: 0.8631068579160659, bias: -0.6956340868183446, loss: 0.5642862543435975\n",
            "Epochs: 1000, w1: 1.026417004139163, w2: 0.8632495543690614, bias: -0.6963559248978864, loss: 0.564223739939057\n",
            "Epochs: 1000, w1: 1.0267051722749687, w2: 0.8633929622233913, bias: -0.6970765729556759, loss: 0.5641613517657146\n",
            "Epochs: 1000, w1: 1.026993785172104, w2: 0.8635370783301395, bias: -0.6977960352257284, loss: 0.5640990889746574\n",
            "Epochs: 1000, w1: 1.027282841127693, w2: 0.8636818995516408, bias: -0.698514315926861, loss: 0.5640369507233193\n",
            "Epochs: 1000, w1: 1.027572338444942, w2: 0.8638274227614501, bias: -0.6992314192627379, loss: 0.5639749361754332\n",
            "Epochs: 1000, w1: 1.0278622754331217, w2: 0.8639736448443114, bias: -0.6999473494219163, loss: 0.5639130445009873\n",
            "Epochs: 1000, w1: 1.0281526504075496, w2: 0.8641205626961265, bias: -0.7006621105778915, loss: 0.5638512748761774\n",
            "Epochs: 1000, w1: 1.0284434616895721, w2: 0.8642681732239237, bias: -0.7013757068891429, loss: 0.5637896264833628\n",
            "Epochs: 1000, w1: 1.0287347076065474, w2: 0.864416473345827, bias: -0.7020881424991785, loss: 0.5637280985110227\n",
            "Epochs: 1000, w1: 1.0290263864918268, w2: 0.8645654599910249, bias: -0.7027994215365811, loss: 0.5636666901537087\n",
            "Epochs: 1000, w1: 1.0293184966847377, w2: 0.8647151300997387, bias: -0.7035095481150533, loss: 0.5636054006120037\n",
            "Epochs: 1000, w1: 1.029611036530566, w2: 0.8648654806231924, bias: -0.7042185263334624, loss: 0.5635442290924754\n",
            "Epochs: 1000, w1: 1.0299040043805376, w2: 0.8650165085235806, bias: -0.7049263602758861, loss: 0.5634831748076347\n",
            "Epochs: 1000, w1: 1.0301973985918018, w2: 0.865168210774038, bias: -0.7056330540116574, loss: 0.5634222369758904\n",
            "Epochs: 1000, w1: 1.030491217527413, w2: 0.8653205843586083, bias: -0.7063386115954099, loss: 0.5633614148215084\n",
            "Epochs: 1000, w1: 1.030785459556313, w2: 0.8654736262722125, bias: -0.7070430370671225, loss: 0.5633007075745661\n",
            "Epochs: 1000, w1: 1.031080123053314, w2: 0.8656273335206186, bias: -0.7077463344521645, loss: 0.5632401144709127\n",
            "Epochs: 1000, w1: 1.0313752063990804, w2: 0.8657817031204101, bias: -0.7084485077613408, loss: 0.5631796347521254\n",
            "Epochs: 1000, w1: 1.0316707079801117, w2: 0.8659367320989552, bias: -0.7091495609909366, loss: 0.5631192676654679\n",
            "Epochs: 1000, w1: 1.0319666261887244, w2: 0.8660924174943753, bias: -0.7098494981227621, loss: 0.5630590124638487\n",
            "Epochs: 1000, w1: 1.032262959423035, w2: 0.8662487563555146, bias: -0.7105483231241972, loss: 0.5629988684057797\n",
            "Epochs: 1000, w1: 1.0325597060869423, w2: 0.8664057457419087, bias: -0.7112460399482369, loss: 0.5629388347553356\n",
            "Epochs: 1000, w1: 1.0328568645901095, w2: 0.8665633827237537, bias: -0.7119426525335348, loss: 0.5628789107821124\n",
            "Epochs: 1000, w1: 1.0331544333479474, w2: 0.8667216643818753, bias: -0.7126381648044489, loss: 0.5628190957611875\n",
            "Epochs: 1000, w1: 1.0334524107815968, w2: 0.8668805878076977, bias: -0.7133325806710851, loss: 0.5627593889730796\n",
            "Epochs: 1000, w1: 1.0337507953179101, w2: 0.8670401501032129, bias: -0.7140259040293423, loss: 0.5626997897037078\n",
            "Epochs: 1000, w1: 1.0340495853894356, w2: 0.8672003483809496, bias: -0.7147181387609567, loss: 0.562640297244353\n",
            "Epochs: 1000, w1: 1.0343487794343982, w2: 0.8673611797639424, bias: -0.715409288733546, loss: 0.5625809108916183\n",
            "Epochs: 1000, w1: 1.0346483758966836, w2: 0.867522641385701, bias: -0.7160993578006537, loss: 0.5625216299473889\n",
            "Epochs: 1000, w1: 1.03494837322582, w2: 0.8676847303901791, bias: -0.7167883498017934, loss: 0.5624624537187944\n",
            "Epochs: 1000, w1: 1.0352487698769612, w2: 0.8678474439317438, bias: -0.7174762685624928, loss: 0.5624033815181702\n",
            "Epochs: 1000, w1: 1.0355495643108692, w2: 0.8680107791751449, bias: -0.718163117894338, loss: 0.562344412663018\n",
            "Epochs: 1000, w1: 1.0358507549938964, w2: 0.8681747332954839, bias: -0.7188489015950174, loss: 0.5622855464759694\n",
            "Epochs: 1000, w1: 1.036152340397969, w2: 0.8683393034781833, bias: -0.7195336234483656, loss: 0.5622267822847463\n",
            "Epochs: 1000, w1: 1.0364543190005697, w2: 0.8685044869189561, bias: -0.7202172872244073, loss: 0.5621681194221252\n",
            "Epochs: 1000, w1: 1.03675668928472, w2: 0.8686702808237748, bias: -0.7208998966794012, loss: 0.5621095572258983\n",
            "Epochs: 1000, w1: 1.0370594497389634, w2: 0.8688366824088409, bias: -0.7215814555558837, loss: 0.5620510950388374\n",
            "Epochs: 1000, w1: 1.037362598857348, w2: 0.8690036889005545, bias: -0.7222619675827125, loss: 0.5619927322086574\n",
            "Epochs: 1000, w1: 1.0376661351394096, w2: 0.869171297535483, bias: -0.7229414364751103, loss: 0.5619344680879791\n",
            "Epochs: 1000, w1: 1.0379700570901542, w2: 0.8693395055603313, bias: -0.7236198659347082, loss: 0.5618763020342925\n",
            "Epochs: 1000, w1: 1.038274363220041, w2: 0.8695083102319111, bias: -0.7242972596495892, loss: 0.5618182334099227\n",
            "Epochs: 1000, w1: 1.0385790520449658, w2: 0.8696777088171099, bias: -0.7249736212943318, loss: 0.5617602615819918\n",
            "Epochs: 1000, w1: 1.0388841220862433, w2: 0.869847698592861, bias: -0.7256489545300531, loss: 0.5617023859223852\n",
            "Epochs: 1000, w1: 1.03918957187059, w2: 0.870018276846113, bias: -0.7263232630044517, loss: 0.5616446058077161\n",
            "Epochs: 1000, w1: 1.039495399930108, w2: 0.8701894408737991, bias: -0.7269965503518517, loss: 0.5615869206192887\n",
            "Epochs: 1000, w1: 1.0398016048022674, w2: 0.8703611879828073, bias: -0.7276688201932451, loss: 0.5615293297430664\n",
            "Epochs: 1000, w1: 1.0401081850298892, w2: 0.8705335154899493, bias: -0.728340076136335, loss: 0.5614718325696345\n",
            "Epochs: 1000, w1: 1.040415139161129, w2: 0.8707064207219309, bias: -0.7290103217755787, loss: 0.5614144284941678\n",
            "Epochs: 1000, w1: 1.0407224657494594, w2: 0.8708799010153214, bias: -0.7296795606922302, loss: 0.5613571169163959\n",
            "Epochs: 1000, w1: 1.0410301633536538, w2: 0.8710539537165232, bias: -0.7303477964543832, loss: 0.5612998972405686\n",
            "Epochs: 1000, w1: 1.041338230537769, w2: 0.8712285761817418, bias: -0.731015032617014, loss: 0.5612427688754245\n",
            "Epochs: 1000, w1: 1.0416466658711285, w2: 0.8714037657769559, bias: -0.7316812727220237, loss: 0.5611857312341549\n",
            "Epochs: 1000, w1: 1.0419554679283063, w2: 0.8715795198778868, bias: -0.7323465202982811, loss: 0.561128783734373\n",
            "Epochs: 1000, w1: 1.0422646352891087, w2: 0.8717558358699689, bias: -0.7330107788616649, loss: 0.5610719257980797\n",
            "Epochs: 1000, w1: 1.0425741665385595, w2: 0.8719327111483187, bias: -0.7336740519151062, loss: 0.561015156851632\n",
            "Epochs: 1000, w1: 1.0428840602668816, w2: 0.872110143117706, bias: -0.7343363429486308, loss: 0.560958476325709\n",
            "Epochs: 1000, w1: 1.0431943150694816, w2: 0.872288129192523, bias: -0.7349976554394017, loss: 0.5609018836552818\n",
            "Epochs: 1000, w1: 1.0435049295469319, w2: 0.8724666667967549, bias: -0.7356579928517604, loss: 0.5608453782795801\n",
            "Epochs: 1000, w1: 1.0438159023049551, w2: 0.8726457533639499, bias: -0.73631735863727, loss: 0.5607889596420604\n",
            "Epochs: 1000, w1: 1.0441272319544073, w2: 0.8728253863371893, bias: -0.7369757562347564, loss: 0.5607326271903758\n",
            "Epochs: 1000, w1: 1.044438917111261, w2: 0.8730055631690576, bias: -0.7376331890703507, loss: 0.5606763803763436\n",
            "Epochs: 1000, w1: 1.0447509563965887, w2: 0.8731862813216132, bias: -0.7382896605575306, loss: 0.5606202186559144\n",
            "Epochs: 1000, w1: 1.0450633484365468, w2: 0.8733675382663582, bias: -0.7389451740971625, loss: 0.5605641414891415\n",
            "Epochs: 1000, w1: 1.045376091862359, w2: 0.8735493314842088, bias: -0.7395997330775428, loss: 0.56050814834015\n",
            "Epochs: 1000, w1: 1.0456891853102994, w2: 0.8737316584654662, bias: -0.7402533408744396, loss: 0.5604522386771076\n",
            "Epochs: 1000, w1: 1.0460026274216767, w2: 0.8739145167097864, bias: -0.7409060008511342, loss: 0.560396411972192\n",
            "Epochs: 1000, w1: 1.0463164168428176, w2: 0.8740979037261509, bias: -0.7415577163584626, loss: 0.5603406677015635\n",
            "Epochs: 1000, w1: 1.0466305522250503, w2: 0.8742818170328376, bias: -0.7422084907348564, loss: 0.5602850053453339\n",
            "Epochs: 1000, w1: 1.0469450322246883, w2: 0.8744662541573907, bias: -0.7428583273063846, loss: 0.5602294243875366\n",
            "Epochs: 1000, w1: 1.0472598555030141, w2: 0.8746512126365916, bias: -0.743507229386794, loss: 0.5601739243160985\n",
            "Epochs: 1000, w1: 1.047575020726263, w2: 0.87483669001643, bias: -0.7441552002775511, loss: 0.5601185046228099\n",
            "Epochs: 1000, w1: 1.0478905265656069, w2: 0.8750226838520742, bias: -0.7448022432678821, loss: 0.5600631648032962\n",
            "Epochs: 1000, w1: 1.048206371697138, w2: 0.8752091917078414, bias: -0.7454483616348146, loss: 0.5600079043569883\n",
            "Epochs: 1000, w1: 1.0485225548018524, w2: 0.8753962111571695, bias: -0.7460935586432179, loss: 0.5599527227870956\n",
            "Epochs: 1000, w1: 1.0488390745656349, w2: 0.8755837397825873, bias: -0.7467378375458437, loss: 0.5598976196005762\n",
            "Epochs: 1000, w1: 1.0491559296792417, w2: 0.8757717751756856, bias: -0.7473812015833668, loss: 0.5598425943081091\n",
            "Epochs: 1000, w1: 1.049473118838285, w2: 0.8759603149370883, bias: -0.748023653984426, loss: 0.5597876464240673\n",
            "Epochs: 1000, w1: 1.0497906407432174, w2: 0.8761493566764229, bias: -0.7486651979656638, loss: 0.5597327754664891\n",
            "Epochs: 1000, w1: 1.0501084940993146, w2: 0.8763388980122923, bias: -0.7493058367317669, loss: 0.5596779809570509\n",
            "Epochs: 1000, w1: 1.0504266776166606, w2: 0.8765289365722452, bias: -0.7499455734755069, loss: 0.5596232624210397\n",
            "Epochs: 1000, w1: 1.0507451900101317, w2: 0.8767194699927479, bias: -0.7505844113777802, loss: 0.5595686193873266\n",
            "Epochs: 1000, w1: 1.0510640299993799, w2: 0.8769104959191549, bias: -0.7512223536076478, loss: 0.5595140513883394\n",
            "Epochs: 1000, w1: 1.0513831963088174, w2: 0.8771020120056808, bias: -0.7518594033223754, loss: 0.5594595579600355\n",
            "Epochs: 1000, w1: 1.0517026876676012, w2: 0.8772940159153712, bias: -0.7524955636674737, loss: 0.5594051386418765\n",
            "Epochs: 1000, w1: 1.0520225028096166, w2: 0.8774865053200739, bias: -0.7531308377767376, loss: 0.5593507929768008\n",
            "Epochs: 1000, w1: 1.052342640473462, w2: 0.877679477900411, bias: -0.753765228772286, loss: 0.5592965205111975\n",
            "Epochs: 1000, w1: 1.0526630994024324, w2: 0.8778729313457498, bias: -0.7543987397646018, loss: 0.5592423207948818\n",
            "Epochs: 1000, w1: 1.052983878344505, w2: 0.8780668633541746, bias: -0.755031373852571, loss: 0.5591881933810673\n",
            "Epochs: 1000, w1: 1.053304976052322, w2: 0.878261271632458, bias: -0.7556631341235224, loss: 0.5591341378263416\n",
            "Epochs: 1000, w1: 1.053626391283177, w2: 0.8784561538960332, bias: -0.7562940236532665, loss: 0.559080153690641\n",
            "Epochs: 1000, w1: 1.0539481227989964, w2: 0.8786515078689646, bias: -0.7569240455061352, loss: 0.5590262405372243\n",
            "Epochs: 1000, w1: 1.054270169366327, w2: 0.8788473312839209, bias: -0.7575532027350209, loss: 0.5589723979326487\n",
            "Epochs: 1000, w1: 1.0545925297563188, w2: 0.8790436218821457, bias: -0.758181498381415, loss: 0.5589186254467448\n",
            "Epochs: 1000, w1: 1.0549152027447093, w2: 0.8792403774134301, bias: -0.7588089354754476, loss: 0.5588649226525914\n",
            "Epochs: 1000, w1: 1.055238187111809, w2: 0.8794375956360845, bias: -0.7594355170359257, loss: 0.5588112891264914\n",
            "Epochs: 1000, w1: 1.0555614816424859, w2: 0.8796352743169102, bias: -0.7600612460703725, loss: 0.5587577244479475\n",
            "Epochs: 1000, w1: 1.0558850851261488, w2: 0.8798334112311722, bias: -0.7606861255750658, loss: 0.5587042281996383\n",
            "Epochs: 1000, w1: 1.0562089963567336, w2: 0.8800320041625702, bias: -0.7613101585350764, loss: 0.5586507999673932\n",
            "Epochs: 1000, w1: 1.0565332141326873, w2: 0.8802310509032119, bias: -0.7619333479243072, loss: 0.5585974393401704\n",
            "Epochs: 1000, w1: 1.0568577372569525, w2: 0.8804305492535842, bias: -0.7625556967055308, loss: 0.5585441459100315\n",
            "Epochs: 1000, w1: 1.0571825645369528, w2: 0.8806304970225265, bias: -0.7631772078304283, loss: 0.5584909192721195\n",
            "Epochs: 1000, w1: 1.0575076947845765, w2: 0.8808308920272019, bias: -0.7637978842396274, loss: 0.5584377590246341\n",
            "Epochs: 1000, w1: 1.0578331268161627, w2: 0.8810317320930704, bias: -0.7644177288627404, loss: 0.5583846647688101\n",
            "Epochs: 1000, w1: 1.0581588594524856, w2: 0.8812330150538611, bias: -0.7650367446184023, loss: 0.5583316361088931\n",
            "Epochs: 1000, w1: 1.058484891518739, w2: 0.8814347387515445, bias: -0.7656549344143087, loss: 0.5582786726521178\n",
            "Epochs: 1000, w1: 1.058811221844522, w2: 0.8816369010363054, bias: -0.7662723011472534, loss: 0.5582257740086849\n",
            "Epochs: 1000, w1: 1.0591378492638237, w2: 0.8818394997665153, bias: -0.7668888477031667, loss: 0.5581729397917383\n",
            "Epochs: 1000, w1: 1.0594647726150077, w2: 0.882042532808705, bias: -0.7675045769571522, loss: 0.5581201696173435\n",
            "Epochs: 1000, w1: 1.059791990740798, w2: 0.8822459980375377, bias: -0.7681194917735252, loss: 0.5580674631044649\n",
            "Epochs: 1000, w1: 1.0601195024882635, w2: 0.8824498933357812, bias: -0.7687335950058494, loss: 0.5580148198749445\n",
            "Epochs: 1000, w1: 1.0604473067088032, w2: 0.8826542165942813, bias: -0.7693468894969745, loss: 0.5579622395534799\n",
            "Epochs: 1000, w1: 1.0607754022581315, w2: 0.8828589657119347, bias: -0.7699593780790738, loss: 0.5579097217676011\n",
            "Epochs: 1000, w1: 1.0611037879962635, w2: 0.8830641385956612, bias: -0.7705710635736807, loss: 0.5578572661476522\n",
            "Epochs: 1000, w1: 1.0614324627875, w2: 0.883269733160378, bias: -0.771181948791726, loss: 0.5578048723267673\n",
            "Epochs: 1000, w1: 1.0617614255004129, w2: 0.8834757473289717, bias: -0.7717920365335752, loss: 0.5577525399408505\n",
            "Epochs: 1000, w1: 1.06209067500783, w2: 0.883682179032272, bias: -0.7724013295890649, loss: 0.5577002686285545\n",
            "Epochs: 1000, w1: 1.0624202101868216, w2: 0.8838890262090247, bias: -0.7730098307375398, loss: 0.5576480580312603\n",
            "Epochs: 1000, w1: 1.0627500299186843, w2: 0.884096286805865, bias: -0.7736175427478892, loss: 0.5575959077930559\n",
            "Epochs: 1000, w1: 1.0630801330889277, w2: 0.8843039587772913, bias: -0.7742244683785835, loss: 0.557543817560716\n",
            "Epochs: 1000, w1: 1.0634105185872589, w2: 0.8845120400856378, bias: -0.7748306103777111, loss: 0.5574917869836818\n",
            "Epochs: 1000, w1: 1.063741185307569, w2: 0.8847205287010484, bias: -0.7754359714830142, loss: 0.55743981571404\n",
            "Epochs: 1000, w1: 1.0640721321479172, w2: 0.8849294226014506, bias: -0.7760405544219257, loss: 0.5573879034065038\n",
            "Epochs: 1000, w1: 1.064403358010518, w2: 0.885138719772528, bias: -0.7766443619116046, loss: 0.5573360497183921\n",
            "Epochs: 1000, w1: 1.0647348618017258, w2: 0.8853484182076952, bias: -0.7772473966589727, loss: 0.5572842543096097\n",
            "Epochs: 1000, w1: 1.0650666424320205, w2: 0.8855585159080707, bias: -0.7778496613607504, loss: 0.5572325168426283\n",
            "Epochs: 1000, w1: 1.0653986988159936, w2: 0.8857690108824509, bias: -0.7784511587034925, loss: 0.5571808369824665\n",
            "Epochs: 1000, w1: 1.0657310298723337, w2: 0.885979901147284, bias: -0.779051891363624, loss: 0.5571292143966701\n",
            "Epochs: 1000, w1: 1.0660636345238121, w2: 0.8861911847266439, bias: -0.7796518620074759, loss: 0.5570776487552936\n",
            "Epochs: 1000, w1: 1.0663965116972691, w2: 0.8864028596522041, bias: -0.7802510732913208, loss: 0.5570261397308812\n",
            "Epochs: 1000, w1: 1.0667296603235994, w2: 0.8866149239632116, bias: -0.780849527861408, loss: 0.5569746869984464\n",
            "Epochs: 1000, w1: 1.0670630793377376, w2: 0.8868273757064612, bias: -0.7814472283539996, loss: 0.5569232902354546\n",
            "Epochs: 1000, w1: 1.067396767678645, w2: 0.8870402129362696, bias: -0.7820441773954051, loss: 0.5568719491218047\n",
            "Epochs: 1000, w1: 1.0677307242892953, w2: 0.8872534337144495, bias: -0.7826403776020171, loss: 0.556820663339809\n",
            "Epochs: 1000, w1: 1.0680649481166595, w2: 0.8874670361102841, bias: -0.783235831580346, loss: 0.5567694325741759\n",
            "Epochs: 1000, w1: 1.0683994381116935, w2: 0.8876810182005012, bias: -0.7838305419270555, loss: 0.556718256511992\n",
            "Epochs: 1000, w1: 1.068734193229323, w2: 0.8878953780692477, bias: -0.7844245112289969, loss: 0.5566671348427025\n",
            "Epochs: 1000, w1: 1.0690692124284302, w2: 0.888110113808064, bias: -0.7850177420632445, loss: 0.5566160672580951\n",
            "Epochs: 1000, w1: 1.0694044946718395, w2: 0.888325223515859, bias: -0.7856102369971297, loss: 0.55656505345228\n",
            "Epochs: 1000, w1: 1.069740038926304, w2: 0.8885407052988836, bias: -0.7862019985882764, loss: 0.5565140931216748\n",
            "Epochs: 1000, w1: 1.0700758441624916, w2: 0.8887565572707068, bias: -0.7867930293846348, loss: 0.556463185964984\n",
            "Epochs: 1000, w1: 1.070411909354971, w2: 0.8889727775521892, bias: -0.787383331924516, loss: 0.5564123316831838\n",
            "Epochs: 1000, w1: 1.0707482334821985, w2: 0.8891893642714584, bias: -0.7879729087366267, loss: 0.5563615299795037\n",
            "Epochs: 1000, w1: 1.0710848155265034, w2: 0.8894063155638839, bias: -0.788561762340103, loss: 0.5563107805594097\n",
            "Epochs: 1000, w1: 1.0714216544740753, w2: 0.8896236295720515, bias: -0.7891498952445445, loss: 0.5562600831305867\n",
            "Epochs: 1000, w1: 1.07175874931495, w2: 0.889841304445739, bias: -0.7897373099500488, loss: 0.5562094374029223\n",
            "Epochs: 1000, w1: 1.0720960990429964, w2: 0.8900593383418904, bias: -0.7903240089472449, loss: 0.5561588430884888\n",
            "Epochs: 1000, w1: 1.0724337026559019, w2: 0.8902777294245919, bias: -0.7909099947173273, loss: 0.5561082999015287\n",
            "Epochs: 1000, w1: 1.0727715591551599, w2: 0.8904964758650465, bias: -0.7914952697320897, loss: 0.5560578075584348\n",
            "Epochs: 1000, w1: 1.073109667546056, w2: 0.8907155758415494, bias: -0.792079836453959, loss: 0.5560073657777376\n",
            "Epochs: 1000, w1: 1.0734480268376547, w2: 0.8909350275394631, bias: -0.7926636973360278, loss: 0.5559569742800853\n",
            "Epochs: 1000, w1: 1.0737866360427857, w2: 0.8911548291511933, bias: -0.7932468548220891, loss: 0.5559066327882304\n",
            "Epochs: 1000, w1: 1.0741254941780305, w2: 0.8913749788761636, bias: -0.7938293113466688, loss: 0.555856341027012\n",
            "Epochs: 1000, w1: 1.07446460026371, w2: 0.8915954749207917, bias: -0.7944110693350593, loss: 0.5558060987233406\n",
            "Epochs: 1000, w1: 1.0748039533238698, w2: 0.8918163154984646, bias: -0.7949921312033527, loss: 0.5557559056061816\n",
            "Epochs: 1000, w1: 1.075143552386268, w2: 0.8920374988295141, bias: -0.7955724993584735, loss: 0.5557057614065403\n",
            "Epochs: 1000, w1: 1.0754833964823618, w2: 0.8922590231411928, bias: -0.796152176198212, loss: 0.5556556658574455\n",
            "Epochs: 1000, w1: 1.075823484647294, w2: 0.8924808866676496, bias: -0.7967311641112569, loss: 0.5556056186939352\n",
            "Epochs: 1000, w1: 1.0761638159198805, w2: 0.8927030876499058, bias: -0.797309465477228, loss: 0.55555561965304\n",
            "Epochs: 1000, w1: 1.076504389342596, w2: 0.8929256243358308, bias: -0.7978870826667094, loss: 0.555505668473768\n",
            "Epochs: 1000, w1: 1.0768452039615626, w2: 0.893148494980118, bias: -0.7984640180412812, loss: 0.55545576489709\n",
            "Epochs: 1000, w1: 1.0771862588265355, w2: 0.8933716978442607, bias: -0.7990402739535527, loss: 0.555405908665925\n",
            "Epochs: 1000, w1: 1.0775275529908903, w2: 0.893595231196529, bias: -0.7996158527471945, loss: 0.5553560995251238\n",
            "Epochs: 1000, w1: 1.0778690855116106, w2: 0.8938190933119446, bias: -0.8001907567569708, loss: 0.555306337221456\n",
            "Epochs: 1000, w1: 1.0782108554492746, w2: 0.8940432824722583, bias: -0.8007649883087716, loss: 0.555256621503593\n",
            "Epochs: 1000, w1: 1.078552861868042, w2: 0.8942677969659253, bias: -0.8013385497196449, loss: 0.5552069521220964\n",
            "Epochs: 1000, w1: 1.0788951038356418, w2: 0.8944926350880822, bias: -0.8019114432978284, loss: 0.5551573288294004\n",
            "Epochs: 1000, w1: 1.0792375804233592, w2: 0.8947177951405231, bias: -0.8024836713427816, loss: 0.5551077513797996\n",
            "Epochs: 1000, w1: 1.0795802907060228, w2: 0.8949432754316761, bias: -0.8030552361452178, loss: 0.5550582195294339\n",
            "Epochs: 1000, w1: 1.079923233761992, w2: 0.8951690742765798, bias: -0.8036261399871354, loss: 0.5550087330362743\n",
            "Epochs: 1000, w1: 1.0802664086731442, w2: 0.8953951899968601, bias: -0.8041963851418497, loss: 0.5549592916601092\n",
            "Epochs: 1000, w1: 1.080609814524862, w2: 0.8956216209207066, bias: -0.8047659738740245, loss: 0.5549098951625298\n",
            "Epochs: 1000, w1: 1.0809534504060212, w2: 0.8958483653828497, bias: -0.8053349084397035, loss: 0.5548605433069173\n",
            "Epochs: 1000, w1: 1.0812973154089778, w2: 0.896075421724537, bias: -0.8059031910863413, loss: 0.5548112358584277\n",
            "Epochs: 1000, w1: 1.0816414086295552, w2: 0.8963027882935104, bias: -0.8064708240528353, loss: 0.5547619725839801\n",
            "Epochs: 1000, w1: 1.081985729167032, w2: 0.8965304634439828, bias: -0.8070378095695561, loss: 0.5547127532522412\n",
            "Epochs: 1000, w1: 1.08233027612413, w2: 0.8967584455366153, bias: -0.8076041498583788, loss: 0.5546635776336127\n",
            "Epochs: 1000, w1: 1.0826750486070011, w2: 0.8969867329384944, bias: -0.8081698471327143, loss: 0.5546144455002188\n",
            "Epochs: 1000, w1: 1.083020045725215, w2: 0.8972153240231088, bias: -0.8087349035975396, loss: 0.5545653566258912\n",
            "Epochs: 1000, w1: 1.083365266591747, w2: 0.8974442171703265, bias: -0.809299321449429, loss: 0.5545163107861575\n",
            "Epochs: 1000, w1: 1.083710710322966, w2: 0.8976734107663727, bias: -0.8098631028765843, loss: 0.5544673077582275\n",
            "Epochs: 1000, w1: 1.0840563760386217, w2: 0.8979029032038065, bias: -0.8104262500588658, loss: 0.5544183473209799\n",
            "Epochs: 1000, w1: 1.0844022628618326, w2: 0.8981326928814982, bias: -0.8109887651678227, loss: 0.5543694292549507\n",
            "Epochs: 1000, w1: 1.0847483699190739, w2: 0.8983627782046074, bias: -0.811550650366723, loss: 0.5543205533423188\n",
            "Epochs: 1000, w1: 1.0850946963401649, w2: 0.89859315758456, bias: -0.8121119078105844, loss: 0.554271719366895\n",
            "Epochs: 1000, w1: 1.0854412412582575, w2: 0.898823829439026, bias: -0.8126725396462042, loss: 0.5542229271141083\n",
            "Epochs: 1000, w1: 1.085788003809824, w2: 0.8990547921918967, bias: -0.8132325480121894, loss: 0.5541741763709933\n",
            "Epochs: 1000, w1: 1.0861349831346443, w2: 0.8992860442732631, bias: -0.8137919350389866, loss: 0.5541254669261794\n",
            "Epochs: 1000, w1: 1.086482178375795, w2: 0.8995175841193932, bias: -0.8143507028489122, loss: 0.5540767985698767\n",
            "Epochs: 1000, w1: 1.0868295886796364, w2: 0.89974941017271, bias: -0.8149088535561818, loss: 0.5540281710938645\n",
            "Epochs: 1000, w1: 1.0871772131958015, w2: 0.8999815208817695, bias: -0.8154663892669404, loss: 0.5539795842914799\n",
            "Epochs: 1000, w1: 1.0875250510771832, w2: 0.9002139147012382, bias: -0.8160233120792915, loss: 0.5539310379576048\n",
            "Epochs: 1000, w1: 1.087873101479923, w2: 0.9004465900918718, bias: -0.816579624083327, loss: 0.5538825318886547\n",
            "Epochs: 1000, w1: 1.088221363563399, w2: 0.9006795455204927, bias: -0.8171353273611566, loss: 0.5538340658825659\n",
            "Epochs: 1000, w1: 1.0885698364902143, w2: 0.9009127794599685, bias: -0.8176904239869369, loss: 0.5537856397387856\n",
            "Epochs: 1000, w1: 1.088918519426185, w2: 0.9011462903891903, bias: -0.8182449160269011, loss: 0.553737253258258\n",
            "Epochs: 1000, w1: 1.0892674115403282, w2: 0.9013800767930505, bias: -0.8187988055393874, loss: 0.5536889062434144\n",
            "Epochs: 1000, w1: 1.089616512004851, w2: 0.9016141371624219, bias: -0.8193520945748691, loss: 0.5536405984981613\n",
            "Epochs: 1000, w1: 1.0899658199951388, w2: 0.9018484699941354, bias: -0.8199047851759826, loss: 0.553592329827869\n",
            "Epochs: 1000, w1: 1.0903153346897425, w2: 0.9020830737909588, bias: -0.8204568793775568, loss: 0.5535441000393596\n",
            "Epochs: 1000, w1: 1.0906650552703687, w2: 0.9023179470615753, bias: -0.8210083792066419, loss: 0.5534959089408975\n",
            "Epochs: 1000, w1: 1.0910149809218668, w2: 0.9025530883205622, bias: -0.8215592866825377, loss: 0.5534477563421765\n",
            "Epochs: 1000, w1: 1.091365110832218, w2: 0.9027884960883698, bias: -0.8221096038168227, loss: 0.5533996420543095\n",
            "Epochs: 1000, w1: 1.0917154441925239, w2: 0.9030241688912991, bias: -0.8226593326133824, loss: 0.5533515658898177\n",
            "Epochs: 1000, w1: 1.0920659801969947, w2: 0.9032601052614821, bias: -0.8232084750684375, loss: 0.55330352766262\n",
            "Epochs: 1000, w1: 1.0924167180429387, w2: 0.9034963037368596, bias: -0.8237570331705727, loss: 0.5532555271880212\n",
            "Epochs: 1000, w1: 1.0927676569307496, w2: 0.9037327628611604, bias: -0.8243050089007644, loss: 0.553207564282702\n",
            "Epochs: 1000, w1: 1.0931187960638962, w2: 0.9039694811838804, bias: -0.8248524042324094, loss: 0.5531596387647089\n",
            "Epochs: 1000, w1: 1.0934701346489109, w2: 0.9042064572602615, bias: -0.8253992211313523, loss: 0.5531117504534422\n",
            "Epochs: 1000, w1: 1.093821671895378, w2: 0.9044436896512709, bias: -0.8259454615559143, loss: 0.5530638991696469\n",
            "Epochs: 1000, w1: 1.0941734070159228, w2: 0.9046811769235802, bias: -0.8264911274569203, loss: 0.5530160847354015\n",
            "Epochs: 1000, w1: 1.0945253392262009, w2: 0.9049189176495446, bias: -0.8270362207777271, loss: 0.5529683069741085\n",
            "Epochs: 1000, w1: 1.0948774677448863, w2: 0.9051569104071822, bias: -0.8275807434542509, loss: 0.552920565710483\n",
            "Epochs: 1000, w1: 1.0952297917936602, w2: 0.9053951537801534, bias: -0.8281246974149952, loss: 0.5528728607705435\n",
            "Epochs: 1000, w1: 1.095582310597201, w2: 0.9056336463577407, bias: -0.8286680845810778, loss: 0.552825191981602\n",
            "Epochs: 1000, w1: 1.0959350233831717, w2: 0.9058723867348274, bias: -0.8292109068662588, loss: 0.552777559172253\n",
            "Epochs: 1000, w1: 1.0962879293822108, w2: 0.9061113735118779, bias: -0.8297531661769675, loss: 0.5527299621723644\n",
            "Epochs: 1000, w1: 1.0966410278279193, w2: 0.906350605294917, bias: -0.8302948644123299, loss: 0.5526824008130672\n",
            "Epochs: 1000, w1: 1.096994317956851, w2: 0.9065900806955095, bias: -0.8308360034641958, loss: 0.5526348749267463\n",
            "Epochs: 1000, w1: 1.0973477990085017, w2: 0.9068297983307403, bias: -0.8313765852171658, loss: 0.5525873843470305\n",
            "Epochs: 1000, w1: 1.0977014702252974, w2: 0.9070697568231938, bias: -0.8319166115486183, loss: 0.552539928908782\n",
            "Epochs: 1000, w1: 1.0980553308525844, w2: 0.9073099548009341, bias: -0.8324560843287363, loss: 0.5524925084480888\n",
            "Epochs: 1000, w1: 1.098409380138618, w2: 0.9075503908974849, bias: -0.8329950054205344, loss: 0.5524451228022536\n",
            "Epochs: 1000, w1: 1.098763617334552, w2: 0.9077910637518093, bias: -0.8335333766798855, loss: 0.5523977718097849\n",
            "Epochs: 1000, w1: 1.0991180416944277, w2: 0.9080319720082899, bias: -0.8340711999555471, loss: 0.5523504553103876\n",
            "Epochs: 1000, w1: 1.0994726524751632, w2: 0.9082731143167092, bias: -0.8346084770891883, loss: 0.5523031731449541\n",
            "Epochs: 1000, w1: 1.0998274489365434, w2: 0.9085144893322296, bias: -0.8351452099154159, loss: 0.552255925155555\n",
            "Epochs: 1000, w1: 1.1001824303412082, w2: 0.9087560957153734, bias: -0.8356814002618008, loss: 0.5522087111854295\n",
            "Epochs: 1000, w1: 1.100537595954643, w2: 0.9089979321320037, bias: -0.8362170499489046, loss: 0.5521615310789765\n",
            "Epochs: 1000, w1: 1.1008929450451679, w2: 0.9092399972533043, bias: -0.8367521607903052, loss: 0.5521143846817466\n",
            "Epochs: 1000, w1: 1.1012484768839266, w2: 0.9094822897557602, bias: -0.8372867345926236, loss: 0.5520672718404316\n",
            "Epochs: 1000, w1: 1.1016041907448764, w2: 0.9097248083211383, bias: -0.8378207731555491, loss: 0.5520201924028568\n",
            "Epochs: 1000, w1: 1.1019600859047778, w2: 0.9099675516364678, bias: -0.8383542782718663, loss: 0.5519731462179721\n",
            "Epochs: 1000, w1: 1.102316161643184, w2: 0.9102105183940209, bias: -0.8388872517274796, loss: 0.5519261331358428\n",
            "Epochs: 1000, w1: 1.1026724172424303, w2: 0.9104537072912933, bias: -0.83941969530144, loss: 0.5518791530076413\n",
            "Epochs: 1000, w1: 1.103028851987624, w2: 0.9106971170309852, bias: -0.8399516107659706, loss: 0.5518322056856387\n",
            "Epochs: 1000, w1: 1.103385465166634, w2: 0.9109407463209821, bias: -0.8404829998864917, loss: 0.5517852910231957\n",
            "Epochs: 1000, w1: 1.1037422560700805, w2: 0.9111845938743354, bias: -0.8410138644216467, loss: 0.5517384088747549\n",
            "Epochs: 1000, w1: 1.1040992239913248, w2: 0.9114286584092434, bias: -0.8415442061233275, loss: 0.5516915590958319\n",
            "Epochs: 1000, w1: 1.104456368226459, w2: 0.9116729386490325, bias: -0.8420740267366995, loss: 0.5516447415430069\n",
            "Epochs: 1000, w1: 1.1048136880742963, w2: 0.9119174333221384, bias: -0.8426033280002273, loss: 0.5515979560739172\n",
            "Epochs: 1000, w1: 1.1051711828363597, w2: 0.9121621411620865, bias: -0.8431321116456993, loss: 0.5515512025472481\n",
            "Epochs: 1000, w1: 1.1055288518168733, w2: 0.9124070609074737, bias: -0.8436603793982536, loss: 0.5515044808227253\n",
            "Epochs: 1000, w1: 1.1058866943227512, w2: 0.9126521913019494, bias: -0.8441881329764019, loss: 0.5514577907611067\n",
            "Epochs: 1000, w1: 1.106244709663588, w2: 0.912897531094197, bias: -0.8447153740920553, loss: 0.5514111322241748\n",
            "Epochs: 1000, w1: 1.106602897151648, w2: 0.9131430790379148, bias: -0.8452421044505487, loss: 0.5513645050747276\n",
            "Epochs: 1000, w1: 1.1069612561018567, w2: 0.9133888338917979, bias: -0.8457683257506656, loss: 0.5513179091765722\n",
            "Epochs: 1000, w1: 1.1073197858317896, w2: 0.9136347944195196, bias: -0.8462940396846628, loss: 0.5512713443945157\n",
            "Epochs: 1000, w1: 1.1076784856616626, w2: 0.9138809593897123, bias: -0.8468192479382947, loss: 0.5512248105943587\n",
            "Epochs: 1000, w1: 1.1080373549143223, w2: 0.91412732757595, bias: -0.8473439521908381, loss: 0.5511783076428866\n",
            "Epochs: 1000, w1: 1.1083963929152358, w2: 0.9143738977567297, bias: -0.8478681541151167, loss: 0.5511318354078619\n",
            "Epochs: 1000, w1: 1.1087555989924813, w2: 0.9146206687154526, bias: -0.8483918553775249, loss: 0.5510853937580177\n",
            "Epochs: 1000, w1: 1.1091149724767382, w2: 0.9148676392404063, bias: -0.8489150576380525, loss: 0.5510389825630493\n",
            "Epochs: 1000, w1: 1.109474512701277, w2: 0.9151148081247467, bias: -0.8494377625503086, loss: 0.5509926016936065\n",
            "Epochs: 1000, w1: 1.1098342190019503, w2: 0.9153621741664796, bias: -0.8499599717615456, loss: 0.550946251021287\n",
            "Epochs: 1000, w1: 1.1101940907171823, w2: 0.9156097361684429, bias: -0.8504816869126836, loss: 0.550899930418629\n",
            "Epochs: 1000, w1: 1.11055412718796, w2: 0.9158574929382884, bias: -0.8510029096383338, loss: 0.5508536397591025\n",
            "Epochs: 1000, w1: 1.1109143277578226, w2: 0.9161054432884643, bias: -0.8515236415668227, loss: 0.5508073789171042\n",
            "Epochs: 1000, w1: 1.1112746917728529, w2: 0.9163535860361965, bias: -0.8520438843202155, loss: 0.550761147767949\n",
            "Epochs: 1000, w1: 1.1116352185816671, w2: 0.9166019200034717, bias: -0.8525636395143399, loss: 0.550714946187863\n",
            "Epochs: 1000, w1: 1.1119959075354056, w2: 0.9168504440170191, bias: -0.8530829087588099, loss: 0.5506687740539763\n",
            "Epochs: 1000, w1: 1.112356757987723, w2: 0.9170991569082927, bias: -0.8536016936570489, loss: 0.5506226312443168\n",
            "Epochs: 1000, w1: 1.1127177692947794, w2: 0.9173480575134539, bias: -0.8541199958063134, loss: 0.5505765176378022\n",
            "Epochs: 1000, w1: 1.1130789408152306, w2: 0.917597144673354, bias: -0.8546378167977161, loss: 0.550530433114234\n",
            "Epochs: 1000, w1: 1.1134402719102188, w2: 0.9178464172335161, bias: -0.8551551582162494, loss: 0.5504843775542899\n",
            "Epochs: 1000, w1: 1.113801761943363, w2: 0.9180958740441183, bias: -0.8556720216408084, loss: 0.5504383508395173\n",
            "Epochs: 1000, w1: 1.1141634102807494, w2: 0.918345513959976, bias: -0.8561884086442139, loss: 0.5503923528523269\n",
            "Epochs: 1000, w1: 1.1145252162909236, w2: 0.9185953358405243, bias: -0.8567043207932357, loss: 0.5503463834759853\n",
            "Epochs: 1000, w1: 1.1148871793448794, w2: 0.9188453385498013, bias: -0.8572197596486153, loss: 0.5503004425946089\n",
            "Epochs: 1000, w1: 1.1152492988160505, w2: 0.9190955209564304, bias: -0.8577347267650889, loss: 0.5502545300931568\n",
            "Epochs: 1000, w1: 1.1156115740803019, w2: 0.9193458819336033, bias: -0.85824922369141, loss: 0.5502086458574253\n",
            "Epochs: 1000, w1: 1.1159740045159192, w2: 0.9195964203590627, bias: -0.8587632519703721, loss: 0.5501627897740402\n",
            "Epochs: 1000, w1: 1.116336589503601, w2: 0.9198471351150855, bias: -0.8592768131388315, loss: 0.5501169617304505\n",
            "Epochs: 1000, w1: 1.116699328426449, w2: 0.9200980250884657, bias: -0.8597899087277298, loss: 0.5500711616149229\n",
            "Epochs: 1000, w1: 1.1170622206699587, w2: 0.9203490891704973, bias: -0.8603025402621161, loss: 0.5500253893165344\n",
            "Epochs: 1000, w1: 1.1174252656220112, w2: 0.9206003262569575, bias: -0.8608147092611695, loss: 0.5499796447251675\n",
            "Epochs: 1000, w1: 1.1177884626728634, w2: 0.9208517352480902, bias: -0.8613264172382218, loss: 0.5499339277315015\n",
            "Epochs: 1000, w1: 1.1181518112151392, w2: 0.9211033150485884, bias: -0.8618376657007789, loss: 0.549888238227009\n",
            "Epochs: 1000, w1: 1.118515310643821, w2: 0.9213550645675784, bias: -0.8623484561505438, loss: 0.5498425761039477\n",
            "Epochs: 1000, w1: 1.1188789603562401, w2: 0.9216069827186026, bias: -0.862858790083438, loss: 0.5497969412553556\n",
            "Epochs: 1000, w1: 1.1192427597520687, w2: 0.9218590684196031, bias: -0.863368668989624, loss: 0.5497513335750438\n",
            "Epochs: 1000, w1: 1.1196067082333097, w2: 0.9221113205929048, bias: -0.8638780943535268, loss: 0.5497057529575918\n",
            "Epochs: 1000, w1: 1.1199708052042894, w2: 0.9223637381651993, bias: -0.864387067653856, loss: 0.5496601992983409\n",
            "Epochs: 1000, w1: 1.1203350500716476, w2: 0.9226163200675285, bias: -0.8648955903636273, loss: 0.5496146724933875\n",
            "Epochs: 1000, w1: 1.1206994422443293, w2: 0.9228690652352677, bias: -0.8654036639501845, loss: 0.5495691724395784\n",
            "Epochs: 1000, w1: 1.1210639811335756, w2: 0.9231219726081097, bias: -0.8659112898752211, loss: 0.5495236990345049\n",
            "Epochs: 1000, w1: 1.1214286661529158, w2: 0.9233750411300485, bias: -0.8664184695948014, loss: 0.549478252176496\n",
            "Epochs: 1000, w1: 1.1217934967181578, w2: 0.9236282697493631, bias: -0.8669252045593823, loss: 0.5494328317646138\n",
            "Epochs: 1000, w1: 1.1221584722473799, w2: 0.923881657418601, bias: -0.8674314962138345, loss: 0.5493874376986471\n",
            "Epochs: 1000, w1: 1.1225235921609222, w2: 0.9241352030945622, bias: -0.8679373459974643, loss: 0.549342069879106\n",
            "Epochs: 1000, w1: 1.1228888558813779, w2: 0.9243889057382837, bias: -0.868442755344034, loss: 0.5492967282072163\n",
            "Epochs: 1000, w1: 1.1232542628335846, w2: 0.9246427643150227, bias: -0.8689477256817837, loss: 0.549251412584914\n",
            "Epochs: 1000, w1: 1.1236198124446164, w2: 0.9248967777942412, bias: -0.8694522584334521, loss: 0.5492061229148397\n",
            "Epochs: 1000, w1: 1.1239855041437745, w2: 0.9251509451495897, bias: -0.8699563550162975, loss: 0.549160859100333\n",
            "Epochs: 1000, w1: 1.1243513373625795, w2: 0.9254052653588919, bias: -0.870460016842119, loss: 0.549115621045427\n",
            "Epochs: 1000, w1: 1.1247173115347626, w2: 0.9256597374041282, bias: -0.8709632453172771, loss: 0.5490704086548436\n",
            "Epochs: 1000, w1: 1.125083426096257, w2: 0.9259143602714207, bias: -0.8714660418427141, loss: 0.5490252218339875\n",
            "Epochs: 1000, w1: 1.12544968048519, w2: 0.9261691329510171, bias: -0.8719684078139759, loss: 0.5489800604889404\n",
            "Epochs: 1000, w1: 1.1258160741418741, w2: 0.926424054437275, bias: -0.8724703446212313, loss: 0.5489349245264574\n",
            "Epochs: 1000, w1: 1.1261826065087999, w2: 0.9266791237286467, bias: -0.8729718536492937, loss: 0.5488898138539602\n",
            "Epochs: 1000, w1: 1.1265492770306258, w2: 0.9269343398276633, bias: -0.8734729362776409, loss: 0.548844728379532\n",
            "Epochs: 1000, w1: 1.1269160851541715, w2: 0.9271897017409195, bias: -0.8739735938804356, loss: 0.5487996680119136\n",
            "Epochs: 1000, w1: 1.127283030328409, w2: 0.9274452084790582, bias: -0.8744738278265461, loss: 0.5487546326604972\n",
            "Epochs: 1000, w1: 1.1276501120044542, w2: 0.9277008590567549, bias: -0.8749736394795662, loss: 0.5487096222353215\n",
            "Epochs: 1000, w1: 1.1280173296355596, w2: 0.9279566524927026, bias: -0.8754730301978354, loss: 0.5486646366470672\n",
            "Epochs: 1000, w1: 1.1283846826771051, w2: 0.9282125878095966, bias: -0.8759720013344594, loss: 0.5486196758070511\n",
            "Epochs: 1000, w1: 1.1287521705865908, w2: 0.928468664034119, bias: -0.8764705542373296, loss: 0.5485747396272221\n",
            "Epochs: 1000, w1: 1.1291197928236283, w2: 0.9287248801969238, bias: -0.8769686902491435, loss: 0.5485298280201557\n",
            "Epochs: 1000, w1: 1.1294875488499327, w2: 0.9289812353326219, bias: -0.8774664107074244, loss: 0.5484849408990492\n",
            "Epochs: 1000, w1: 1.1298554381293149, w2: 0.9292377284797657, bias: -0.8779637169445413, loss: 0.5484400781777171\n",
            "Epochs: 1000, w1: 1.130223460127673, w2: 0.9294943586808346, bias: -0.8784606102877289, loss: 0.5483952397705862\n",
            "Epochs: 1000, w1: 1.1305916143129855, w2: 0.9297511249822196, bias: -0.8789570920591068, loss: 0.5483504255926905\n",
            "Epochs: 1000, w1: 1.130959900155302, w2: 0.9300080264342085, bias: -0.8794531635756994, loss: 0.5483056355596673\n",
            "Epochs: 1000, w1: 1.1313283171267356, w2: 0.9302650620909717, bias: -0.8799488261494555, loss: 0.5482608695877514\n",
            "Epochs: 1000, w1: 1.1316968647014563, w2: 0.9305222310105462, bias: -0.8804440810872678, loss: 0.5482161275937715\n",
            "Epochs: 1000, w1: 1.132065542355681, w2: 0.930779532254822, bias: -0.8809389296909921, loss: 0.5481714094951449\n",
            "Epochs: 1000, w1: 1.1324343495676674, w2: 0.9310369648895269, bias: -0.8814333732574667, loss: 0.5481267152098727\n",
            "Epochs: 1000, w1: 1.1328032858177055, w2: 0.931294527984212, bias: -0.8819274130785321, loss: 0.548082044656537\n",
            "Epochs: 1000, w1: 1.1331723505881097, w2: 0.931552220612237, bias: -0.8824210504410493, loss: 0.5480373977542938\n",
            "Epochs: 1000, w1: 1.1335415433632114, w2: 0.9318100418507557, bias: -0.8829142866269202, loss: 0.5479927744228704\n",
            "Epochs: 1000, w1: 1.1339108636293511, w2: 0.9320679907807018, bias: -0.8834071229131051, loss: 0.5479481745825604\n",
            "Epochs: 1000, w1: 1.1342803108748707, w2: 0.9323260664867741, bias: -0.8838995605716432, loss: 0.5479035981542191\n",
            "Epochs: 1000, w1: 1.1346498845901059, w2: 0.9325842680574222, bias: -0.8843916008696706, loss: 0.5478590450592592\n",
            "Epochs: 1000, w1: 1.1350195842673785, w2: 0.9328425945848325, bias: -0.8848832450694394, loss: 0.5478145152196471\n",
            "Epochs: 1000, w1: 1.1353894094009889, w2: 0.9331010451649137, bias: -0.8853744944283366, loss: 0.5477700085578978\n",
            "Epochs: 1000, w1: 1.1357593594872082, w2: 0.9333596188972823, bias: -0.8858653501989028, loss: 0.5477255249970705\n",
            "Epochs: 1000, w1: 1.1361294340242711, w2: 0.9336183148852488, bias: -0.8863558136288506, loss: 0.5476810644607653\n",
            "Epochs: 1000, w1: 1.136499632512368, w2: 0.9338771322358036, bias: -0.8868458859610836, loss: 0.5476366268731185\n",
            "Epochs: 1000, w1: 1.1368699544536376, w2: 0.9341360700596028, bias: -0.8873355684337145, loss: 0.547592212158798\n",
            "Epochs: 1000, w1: 1.1372403993521596, w2: 0.934395127470954, bias: -0.8878248622800838, loss: 0.547547820243\n",
            "Epochs: 1000, w1: 1.137610966713947, w2: 0.9346543035878027, bias: -0.8883137687287783, loss: 0.547503451051444\n",
            "Epochs: 1000, w1: 1.1379816560469387, w2: 0.9349135975317179, bias: -0.888802289003649, loss: 0.5474591045103696\n",
            "Epochs: 1000, w1: 1.1383524668609923, w2: 0.9351730084278789, bias: -0.8892904243238298, loss: 0.547414780546532\n",
            "Epochs: 1000, w1: 1.1387233986678766, w2: 0.9354325354050608, bias: -0.8897781759037553, loss: 0.547370479087198\n",
            "Epochs: 1000, w1: 1.1390944509812644, w2: 0.9356921775956211, bias: -0.8902655449531794, loss: 0.5473262000601418\n",
            "Epochs: 1000, w1: 1.1394656233167246, w2: 0.9359519341354858, bias: -0.8907525326771929, loss: 0.5472819433936418\n",
            "Epochs: 1000, w1: 1.139836915191716, w2: 0.936211804164136, bias: -0.8912391402762415, loss: 0.5472377090164756\n",
            "Epochs: 1000, w1: 1.1402083261255789, w2: 0.9364717868245936, bias: -0.8917253689461441, loss: 0.5471934968579173\n",
            "Epochs: 1000, w1: 1.1405798556395284, w2: 0.9367318812634088, bias: -0.8922112198781103, loss: 0.5471493068477329\n",
            "Epochs: 1000, w1: 1.1409515032566475, w2: 0.9369920866306454, bias: -0.8926966942587583, loss: 0.5471051389161764\n",
            "Epochs: 1000, w1: 1.1413232685018793, w2: 0.937252402079868, bias: -0.8931817932701329, loss: 0.5470609929939866\n",
            "Epochs: 1000, w1: 1.14169515090202, w2: 0.9375128267681287, bias: -0.8936665180897226, loss: 0.5470168690123827\n",
            "Epochs: 1000, w1: 1.1420671499857118, w2: 0.9377733598559532, bias: -0.8941508698904777, loss: 0.5469727669030608\n",
            "Epochs: 1000, w1: 1.1424392652834363, w2: 0.9380340005073277, bias: -0.8946348498408273, loss: 0.5469286865981906\n",
            "Epochs: 1000, w1: 1.1428114963275067, w2: 0.9382947478896854, bias: -0.8951184591046976, loss: 0.5468846280304112\n",
            "Epochs: 1000, w1: 1.1431838426520609, w2: 0.9385556011738937, bias: -0.8956016988415284, loss: 0.5468405911328269\n",
            "Epochs: 1000, w1: 1.143556303793055, w2: 0.9388165595342407, bias: -0.8960845702062912, loss: 0.5467965758390056\n",
            "Epochs: 1000, w1: 1.1439288792882552, w2: 0.9390776221484219, bias: -0.8965670743495057, loss: 0.5467525820829731\n",
            "Epochs: 1000, w1: 1.144301568677232, w2: 0.9393387881975276, bias: -0.8970492124172577, loss: 0.5467086097992101\n",
            "Epochs: 1000, w1: 1.1446743715013528, w2: 0.9396000568660291, bias: -0.897530985551216, loss: 0.5466646589226495\n",
            "Epochs: 1000, w1: 1.1450472873037747, w2: 0.9398614273417664, bias: -0.8980123948886495, loss: 0.5466207293886719\n",
            "Epochs: 1000, w1: 1.1454203156294378, w2: 0.9401228988159348, bias: -0.8984934415624439, loss: 0.5465768211331028\n",
            "Epochs: 1000, w1: 1.1457934560250584, w2: 0.9403844704830722, bias: -0.8989741267011193, loss: 0.5465329340922082\n",
            "Epochs: 1000, w1: 1.146166708039122, w2: 0.940646141541046, bias: -0.8994544514288466, loss: 0.5464890682026926\n",
            "Epochs: 1000, w1: 1.1465400712218767, w2: 0.9409079111910404, bias: -0.8999344168654645, loss: 0.5464452234016942\n",
            "Epochs: 1000, w1: 1.146913545125326, w2: 0.9411697786375439, bias: -0.9004140241264963, loss: 0.5464013996267827\n",
            "Epochs: 1000, w1: 1.1472871293032227, w2: 0.941431743088336, bias: -0.9008932743231666, loss: 0.546357596815955\n",
            "Epochs: 1000, w1: 1.1476608233110612, w2: 0.9416938037544749, bias: -0.9013721685624179, loss: 0.5463138149076323\n",
            "Epochs: 1000, w1: 1.1480346267060715, w2: 0.9419559598502846, bias: -0.9018507079469271, loss: 0.5462700538406569\n",
            "Epochs: 1000, w1: 1.1484085390472123, w2: 0.9422182105933427, bias: -0.9023288935751224, loss: 0.5462263135542884\n",
            "Epochs: 1000, w1: 1.1487825598951642, w2: 0.9424805552044674, bias: -0.9028067265411993, loss: 0.5461825939882019\n",
            "Epochs: 1000, w1: 1.1491566888123232, w2: 0.9427429929077054, bias: -0.9032842079351374, loss: 0.5461388950824824\n",
            "Epochs: 1000, w1: 1.149530925362794, w2: 0.943005522930319, bias: -0.9037613388427164, loss: 0.5460952167776238\n",
            "Epochs: 1000, w1: 1.1499052691123834, w2: 0.9432681445027741, bias: -0.9042381203455326, loss: 0.5460515590145247\n",
            "Epochs: 1000, w1: 1.1502797196285937, w2: 0.9435308568587273, bias: -0.9047145535210153, loss: 0.5460079217344853\n",
            "Epochs: 1000, w1: 1.150654276480616, w2: 0.9437936592350143, bias: -0.9051906394424424, loss: 0.5459643048792043\n",
            "Epochs: 1000, w1: 1.1510289392393243, w2: 0.9440565508716371, bias: -0.9056663791789571, loss: 0.5459207083907764\n",
            "Epochs: 1000, w1: 1.1514037074772678, w2: 0.9443195310117516, bias: -0.9061417737955836, loss: 0.5458771322116885\n",
            "Epochs: 1000, w1: 1.1517785807686658, w2: 0.944582598901656, bias: -0.9066168243532432, loss: 0.5458335762848164\n",
            "Epochs: 1000, w1: 1.1521535586894, w2: 0.9448457537907782, bias: -0.9070915319087702, loss: 0.5457900405534232\n",
            "Epochs: 1000, w1: 1.152528640817009, w2: 0.9451089949316639, bias: -0.9075658975149278, loss: 0.5457465249611544\n",
            "Epochs: 1000, w1: 1.1529038267306813, w2: 0.9453723215799643, bias: -0.9080399222204238, loss: 0.5457030294520367\n",
            "Epochs: 1000, w1: 1.153279116011249, w2: 0.9456357329944244, bias: -0.9085136070699267, loss: 0.5456595539704737\n",
            "Epochs: 1000, w1: 1.1536545082411818, w2: 0.9458992284368707, bias: -0.9089869531040807, loss: 0.5456160984612439\n",
            "Epochs: 1000, w1: 1.1540300030045803, w2: 0.9461628071721996, bias: -0.9094599613595222, loss: 0.5455726628694969\n",
            "Epochs: 1000, w1: 1.1544055998871696, w2: 0.9464264684683651, bias: -0.9099326328688947, loss: 0.5455292471407517\n",
            "Epochs: 1000, w1: 1.1547812984762935, w2: 0.9466902115963673, bias: -0.9104049686608646, loss: 0.5454858512208925\n",
            "Epochs: 1000, w1: 1.1551570983609076, w2: 0.9469540358302407, bias: -0.9108769697601365, loss: 0.5454424750561672\n",
            "Epochs: 1000, w1: 1.1555329991315735, w2: 0.9472179404470419, bias: -0.9113486371874691, loss: 0.5453991185931829\n",
            "Epochs: 1000, w1: 1.155909000380452, w2: 0.9474819247268382, bias: -0.9118199719596896, loss: 0.5453557817789051\n",
            "Epochs: 1000, w1: 1.156285101701298, w2: 0.9477459879526963, bias: -0.9122909750897098, loss: 0.5453124645606535\n",
            "Epochs: 1000, w1: 1.1566613026894532, w2: 0.9480101294106698, bias: -0.9127616475865413, loss: 0.5452691668860998\n",
            "Epochs: 1000, w1: 1.1570376029418403, w2: 0.9482743483897884, bias: -0.9132319904553102, loss: 0.5452258887032648\n",
            "Epochs: 1000, w1: 1.1574140020569572, w2: 0.9485386441820461, bias: -0.9137020046972726, loss: 0.5451826299605153\n",
            "Epochs: 1000, w1: 1.1577904996348702, w2: 0.9488030160823896, bias: -0.9141716913098292, loss: 0.5451393906065626\n",
            "Epochs: 1000, w1: 1.158167095277209, w2: 0.9490674633887066, bias: -0.9146410512865412, loss: 0.5450961705904587\n",
            "Epochs: 1000, w1: 1.158543788587159, w2: 0.9493319854018152, bias: -0.915110085617144, loss: 0.5450529698615941\n",
            "Epochs: 1000, w1: 1.158920579169457, w2: 0.9495965814254514, bias: -0.9155787952875635, loss: 0.5450097883696953\n",
            "Epochs: 1000, w1: 1.1592974666303841, w2: 0.9498612507662588, bias: -0.9160471812799296, loss: 0.5449666260648213\n",
            "Epochs: 1000, w1: 1.1596744505777599, w2: 0.9501259927337766, bias: -0.9165152445725918, loss: 0.5449234828973627\n",
            "Epochs: 1000, w1: 1.1600515306209365, w2: 0.9503908066404287, bias: -0.916982986140134, loss: 0.5448803588180374\n",
            "Epochs: 1000, w1: 1.160428706370793, w2: 0.9506556918015124, bias: -0.9174504069533883, loss: 0.5448372537778894\n",
            "Epochs: 1000, w1: 1.1608059774397288, w2: 0.9509206475351871, bias: -0.9179175079794507, loss: 0.5447941677282855\n",
            "Epochs: 1000, w1: 1.1611833434416583, w2: 0.9511856731624633, bias: -0.9183842901816949, loss: 0.5447511006209124\n",
            "Epochs: 1000, w1: 1.1615608039920047, w2: 0.9514507680071915, bias: -0.9188507545197871, loss: 0.544708052407776\n",
            "Epochs: 1000, w1: 1.1619383587076944, w2: 0.9517159313960512, bias: -0.9193169019497006, loss: 0.5446650230411964\n",
            "Epochs: 1000, w1: 1.1623160072071506, w2: 0.9519811626585396, bias: -0.9197827334237297, loss: 0.5446220124738079\n",
            "Epochs: 1000, w1: 1.1626937491102882, w2: 0.9522464611269612, bias: -0.9202482498905046, loss: 0.544579020658555\n",
            "Epochs: 1000, w1: 1.1630715840385075, w2: 0.9525118261364163, bias: -0.9207134522950053, loss: 0.5445360475486906\n",
            "Epochs: 1000, w1: 1.1634495116146886, w2: 0.9527772570247902, bias: -0.9211783415785761, loss: 0.5444930930977732\n",
            "Epochs: 1000, w1: 1.1638275314631854, w2: 0.9530427531327428, bias: -0.9216429186789395, loss: 0.5444501572596651\n",
            "Epochs: 1000, w1: 1.1642056432098205, w2: 0.9533083138036972, bias: -0.9221071845302108, loss: 0.5444072399885296\n",
            "Epochs: 1000, w1: 1.1645838464818785, w2: 0.9535739383838293, bias: -0.9225711400629114, loss: 0.5443643412388286\n",
            "Epochs: 1000, w1: 1.1649621409081015, w2: 0.953839626222057, bias: -0.9230347862039836, loss: 0.5443214609653215\n",
            "Epochs: 1000, w1: 1.165340526118682, w2: 0.9541053766700295, bias: -0.9234981238768043, loss: 0.5442785991230604\n",
            "Epochs: 1000, w1: 1.1657190017452586, w2: 0.9543711890821166, bias: -0.9239611540011986, loss: 0.5442357556673908\n",
            "Epochs: 1000, w1: 1.1660975674209093, w2: 0.9546370628153982, bias: -0.9244238774934542, loss: 0.5441929305539468\n",
            "Epochs: 1000, w1: 1.1664762227801468, w2: 0.9549029972296534, bias: -0.9248862952663349, loss: 0.5441501237386505\n",
            "Epochs: 1000, w1: 1.1668549674589126, w2: 0.9551689916873506, bias: -0.9253484082290944, loss: 0.5441073351777089\n",
            "Epochs: 1000, w1: 1.1672338010945706, w2: 0.9554350455536362, bias: -0.9258102172874898, loss: 0.5440645648276123\n",
            "Epochs: 1000, w1: 1.1676127233259028, w2: 0.955701158196325, bias: -0.9262717233437958, loss: 0.5440218126451316\n",
            "Epochs: 1000, w1: 1.1679917337931032, w2: 0.9559673289858889, bias: -0.9267329272968178, loss: 0.5439790785873165\n",
            "Epochs: 1000, w1: 1.168370832137772, w2: 0.9562335572954473, bias: -0.9271938300419056, loss: 0.543936362611493\n",
            "Epochs: 1000, w1: 1.1687500180029107, w2: 0.9564998425007565, bias: -0.9276544324709671, loss: 0.5438936646752615\n",
            "Epochs: 1000, w1: 1.1691292910329163, w2: 0.956766183980199, bias: -0.9281147354724816, loss: 0.5438509847364944\n",
            "Epochs: 1000, w1: 1.169508650873576, w2: 0.9570325811147737, bias: -0.9285747399315128, loss: 0.543808322753335\n",
            "Epochs: 1000, w1: 1.1698880971720615, w2: 0.9572990332880857, bias: -0.929034446729723, loss: 0.5437656786841938\n",
            "Epochs: 1000, w1: 1.170267629576924, w2: 0.9575655398863359, bias: -0.9294938567453858, loss: 0.5437230524877473\n",
            "Epochs: 1000, w1: 1.1706472477380887, w2: 0.9578321002983106, bias: -0.9299529708533992, loss: 0.5436804441229367\n",
            "Epochs: 1000, w1: 1.1710269513068488, w2: 0.9580987139153722, bias: -0.9304117899252996, loss: 0.5436378535489638\n",
            "Epochs: 1000, w1: 1.171406739935861, w2: 0.9583653801314482, bias: -0.930870314829274, loss: 0.5435952807252914\n",
            "Epochs: 1000, w1: 1.1717866132791401, w2: 0.9586320983430219, bias: -0.9313285464301736, loss: 0.5435527256116395\n",
            "Epochs: 1000, w1: 1.1721665709920532, w2: 0.9588988679491218, bias: -0.931786485589527, loss: 0.543510188167984\n",
            "Epochs: 1000, w1: 1.1725466127313149, w2: 0.9591656883513122, bias: -0.9322441331655529, loss: 0.543467668354555\n",
            "Epochs: 1000, w1: 1.1729267381549815, w2: 0.9594325589536828, bias: -0.9327014900131729, loss: 0.5434251661318337\n",
            "Epochs: 1000, w1: 1.1733069469224462, w2: 0.9596994791628393, bias: -0.933158556984025, loss: 0.5433826814605524\n",
            "Epochs: 1000, w1: 1.173687238694434, w2: 0.9599664483878927, bias: -0.9336153349264757, loss: 0.5433402143016901\n",
            "Epochs: 1000, w1: 1.1740676131329957, w2: 0.9602334660404506, bias: -0.9340718246856335, loss: 0.5432977646164732\n",
            "Epochs: 1000, w1: 1.1744480699015036, w2: 0.9605005315346066, bias: -0.9345280271033612, loss: 0.5432553323663715\n",
            "Epochs: 1000, w1: 1.1748286086646462, w2: 0.960767644286931, bias: -0.9349839430182888, loss: 0.5432129175130972\n",
            "Epochs: 1000, w1: 1.1752092290884224, w2: 0.9610348037164607, bias: -0.9354395732658259, loss: 0.5431705200186031\n",
            "Epochs: 1000, w1: 1.175589930840137, w2: 0.9613020092446898, bias: -0.935894918678175, loss: 0.5431281398450805\n",
            "Epochs: 1000, w1: 1.1759707135883954, w2: 0.9615692602955601, bias: -0.936349980084343, loss: 0.5430857769549574\n",
            "Epochs: 1000, w1: 1.1763515770030988, w2: 0.9618365562954513, bias: -0.9368047583101546, loss: 0.5430434313108972\n",
            "Epochs: 1000, w1: 1.1767325207554382, w2: 0.9621038966731712, bias: -0.9372592541782646, loss: 0.5430011028757957\n",
            "Epochs: 1000, w1: 1.1771135445178904, w2: 0.9623712808599467, bias: -0.9377134685081698, loss: 0.5429587916127802\n",
            "Epochs: 1000, w1: 1.1774946479642128, w2: 0.962638708289414, bias: -0.9381674021162222, loss: 0.542916497485208\n",
            "Epochs: 1000, w1: 1.1778758307694377, w2: 0.9629061783976092, bias: -0.9386210558156404, loss: 0.5428742204566634\n",
            "Epochs: 1000, w1: 1.178257092609868, w2: 0.9631736906229588, bias: -0.9390744304165226, loss: 0.5428319604909576\n",
            "Epochs: 1000, w1: 1.1786384331630722, w2: 0.9634412444062704, bias: -0.9395275267258587, loss: 0.5427897175521252\n",
            "Epochs: 1000, w1: 1.1790198521078785, w2: 0.9637088391907235, bias: -0.9399803455475422, loss: 0.5427474916044237\n",
            "Epochs: 1000, w1: 1.1794013491243713, w2: 0.9639764744218597, bias: -0.9404328876823824, loss: 0.5427052826123316\n",
            "Epochs: 1000, w1: 1.1797829238938853, w2: 0.9642441495475743, bias: -0.940885153928117, loss: 0.5426630905405463\n",
            "Epochs: 1000, w1: 1.180164576099001, w2: 0.964511864018106, bias: -0.9413371450794233, loss: 0.5426209153539823\n",
            "Epochs: 1000, w1: 1.1805463054235394, w2: 0.9647796172860283, bias: -0.941788861927931, loss: 0.5425787570177705\n",
            "Epochs: 1000, w1: 1.180928111552558, w2: 0.9650474088062406, bias: -0.9422403052622333, loss: 0.5425366154972557\n",
            "Epochs: 1000, w1: 1.181309994172345, w2: 0.9653152380359582, bias: -0.9426914758679, loss: 0.5424944907579947\n",
            "Epochs: 1000, w1: 1.1816919529704148, w2: 0.965583104434704, bias: -0.9431423745274882, loss: 0.5424523827657555\n",
            "Epochs: 1000, w1: 1.1820739876355033, w2: 0.965851007464299, bias: -0.9435930020205545, loss: 0.5424102914865153\n",
            "Epochs: 1000, w1: 1.1824560978575633, w2: 0.9661189465888533, bias: -0.9440433591236672, loss: 0.5423682168864589\n",
            "Epochs: 1000, w1: 1.1828382833277593, w2: 0.9663869212747574, bias: -0.9444934466104175, loss: 0.5423261589319762\n",
            "Epochs: 1000, w1: 1.183220543738463, w2: 0.9666549309906729, bias: -0.9449432652514314, loss: 0.5422841175896633\n",
            "Epochs: 1000, w1: 1.1836028787832487, w2: 0.9669229752075235, bias: -0.9453928158143812, loss: 0.5422420928263172\n",
            "Epochs: 1000, w1: 1.1839852881568877, w2: 0.9671910533984864, bias: -0.9458420990639974, loss: 0.5422000846089374\n",
            "Epochs: 1000, w1: 1.1843677715553453, w2: 0.9674591650389835, bias: -0.9462911157620799, loss: 0.5421580929047227\n",
            "Epochs: 1000, w1: 1.1847503286757746, w2: 0.9677273096066721, bias: -0.9467398666675096, loss: 0.5421161176810698\n",
            "Epochs: 1000, w1: 1.1851329592165123, w2: 0.9679954865814364, bias: -0.9471883525362601, loss: 0.5420741589055725\n",
            "Epochs: 1000, w1: 1.1855156628770742, w2: 0.9682636954453788, bias: -0.9476365741214088, loss: 0.5420322165460195\n",
            "Epochs: 1000, w1: 1.1858984393581506, w2: 0.968531935682811, bias: -0.9480845321731484, loss: 0.5419902905703936\n",
            "Epochs: 1000, w1: 1.1862812883616014, w2: 0.9688002067802454, bias: -0.9485322274387981, loss: 0.5419483809468686\n",
            "Epochs: 1000, w1: 1.1866642095904516, w2: 0.9690685082263861, bias: -0.9489796606628152, loss: 0.5419064876438102\n",
            "Epochs: 1000, w1: 1.1870472027488872, w2: 0.9693368395121211, bias: -0.9494268325868063, loss: 0.5418646106297728\n",
            "Epochs: 1000, w1: 1.18743026754225, w2: 0.9696052001305129, bias: -0.9498737439495379, loss: 0.5418227498734983\n",
            "Epochs: 1000, w1: 1.1878134036770331, w2: 0.9698735895767899, bias: -0.9503203954869485, loss: 0.5417809053439155\n",
            "Epochs: 1000, w1: 1.1881966108608772, w2: 0.9701420073483386, bias: -0.9507667879321587, loss: 0.5417390770101376\n",
            "Epochs: 1000, w1: 1.188579888802565, w2: 0.9704104529446941, bias: -0.9512129220154832, loss: 0.5416972648414616\n",
            "Epochs: 1000, w1: 1.188963237212017, w2: 0.9706789258675327, bias: -0.9516587984644413, loss: 0.5416554688073664\n",
            "Epochs: 1000, w1: 1.1893466558002879, w2: 0.9709474256206626, bias: -0.9521044180037681, loss: 0.5416136888775112\n",
            "Epochs: 1000, w1: 1.189730144279561, w2: 0.971215951710016, bias: -0.9525497813554251, loss: 0.5415719250217351\n",
            "Epochs: 1000, w1: 1.1901137023631443, w2: 0.9714845036436403, bias: -0.9529948892386115, loss: 0.5415301772100549\n",
            "Epochs: 1000, w1: 1.1904973297654662, w2: 0.9717530809316901, bias: -0.9534397423697749, loss: 0.541488445412664\n",
            "Epochs: 1000, w1: 1.1908810262020706, w2: 0.9720216830864188, bias: -0.9538843414626222, loss: 0.5414467295999306\n",
            "Epochs: 1000, w1: 1.1912647913896133, w2: 0.9722903096221702, bias: -0.9543286872281302, loss: 0.541405029742397\n",
            "Epochs: 1000, w1: 1.1916486250458567, w2: 0.9725589600553705, bias: -0.9547727803745565, loss: 0.5413633458107777\n",
            "Epochs: 1000, w1: 1.192032526889666, w2: 0.9728276339045195, bias: -0.95521662160745, loss: 0.5413216777759594\n",
            "Epochs: 1000, w1: 1.1924164966410051, w2: 0.9730963306901833, bias: -0.9556602116296619, loss: 0.5412800256089975\n",
            "Epochs: 1000, w1: 1.1928005340209318, w2: 0.9733650499349854, bias: -0.9561035511413558, loss: 0.5412383892811162\n",
            "Epochs: 1000, w1: 1.1931846387515932, w2: 0.9736337911635988, bias: -0.956546640840019, loss: 0.5411967687637079\n",
            "Epochs: 1000, w1: 1.1935688105562225, w2: 0.973902553902738, bias: -0.9569894814204721, loss: 0.5411551640283299\n",
            "Epochs: 1000, w1: 1.193953049159134, w2: 0.9741713376811509, bias: -0.9574320735748804, loss: 0.5411135750467048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.193953049159134, 0.9741713376811509, -0.9574320735748804)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}